var store = [{
        "title": "Seguridad Empresarial con Red Hat: Más Allá del Código Abierto",
        "excerpt":"El Paradigma de la Seguridad en el Open Source   El software de código abierto se ha convertido en una pieza clave para impulsar la innovación tecnológica. Su esencia está en la colaboración y la transparencia, lo que ha permitido avances extraordinarios, pero aquí es donde aparece lo que podríamos llamar el dilema del código abierto. Aunque este modelo colaborativo es su mayor fortaleza, también plantea desafíos cuando se trata de adoptarlo a nivel empresarial. No es el código en sí el problema, sino cómo las organizaciones entienden y, sobre todo, cómo gestionan su seguridad y los riesgos asociados.   El panorama de las vulnerabilidades ha cambiado radicalmente en las últimas décadas. Cuando nació el programa Common Vulnerabilities and Exposures (CVE) hace 25 años, se registraron 894 vulnerabilidades de seguridad en su primer año, estamos hablando de 1999. En 2024, esa cifra superó las 40,000. Este crecimiento exponencial ha dejado obsoleta la vieja estrategia de ‘parchearlo todo’, ya no es viable ni inteligente tratar todas las vulnerabilidades por igual. No todos los fallos representan el mismo nivel de riesgo, y centrarse en corregirlos todos sin priorizar ignora un punto clave, si realmente están siendo explotados o no. De hecho, los datos muestran que históricamente menos del 0.5% de las vulnerabilidades llegan a ser explotadas activamente.      Aquí es donde la transparencia del código abierto puede jugar en contra, al ser públicos por naturaleza, los proyectos open source tienden a reportar y documentar una gran cantidad de fallos, incluso los de impacto bajo o moderado, en cambio, muchos proveedores de software propietario no revelan este tipo de vulnerabilidades menores, lo que crea una ilusión de mayor seguridad y un panorama de riesgo mucho más opaco.   Esto da lugar a un doble estándar, las políticas que exigen “Zero Known Vulnerabilities” terminan castigando al código abierto por ser más transparente, en lugar de enfocarse en lo que realmente importa, el riesgo real. Red Hat Product Security Risk Report 2024 lo deja claro. Aunque en 2024 aumentó notablemente el número de CVEs asignados a productos de Red Hat en parte porque el kernel de Linux empezó a funcionar como autoridad oficial para registrar fallos (CNA), el riesgo real detrás de esos números no cambió mucho, la mayoría de esas nuevas vulnerabilidades eran de bajo o moderado impacto, lo que refuerza una idea clave, necesitamos evaluar el riesgo con criterio, no simplemente contar vulnerabilidades.   El caso de XZ Backdoor, también abordado en el informe, fue una verdadera llamada de atención a nivel global sobre lo sofisticados que se han vuelto los ataques a la cadena de suministro de software (SSCA). Un atacante logró infiltrarse durante casi dos años, ganándose la confianza de la comunidad, hasta que finalmente introdujo código malicioso con el potencial de comprometer una enorme cantidad de sistemas.   Este incidente puso en evidencia lo crítica que es la seguridad en la cadena de suministro. Pero también dejó algo muy claro, el modelo de código abierto tiene una fortaleza única, gracias a la transparencia del código, la comunidad detectó y reaccionó rápidamente de forma colaborativa, esa respuesta ágil y abierta fue clave para contener la amenaza a tiempo.   Red Hat no se limita a usar software de código abierto, participa activamente en su evolución, lo mantiene y lo fortalece, es un actor clave dentro del ecosistema, con un conocimiento profundo de las normativas globales y una visión anticipada de las amenazas emergentes, Red Hat incorpora la seguridad desde el inicio y a lo largo de todo su ciclo de desarrollo de software (RHSDLC).   Además, su rol como participante raíz del programa CVE y CNA lo coloca en una posición única, no solo identifica y evalúa vulnerabilidades, sino que ofrece a sus clientes soluciones concretas y respaldadas por un nivel de experiencia difícil de igualar.   Las organizaciones necesitan más que solo software de código abierto, necesitan una plataforma open source reforzada, gestionada y segura por diseño, aquí es donde los productos de Red Hat marcan la diferencia.   Red Hat Enterprise Linux (RHEL): La Base Reforzada   Toda estrategia de seguridad empresarial robusta debe construirse sobre una base sólida, en el ecosistema de Red Hat, esa base es Red Hat Enterprise Linux (RHEL), no todas las distribuciones de Linux son iguales en lo que a seguridad se refiere. RHEL se distingue por un enfoque proactivo que abarca desde el cumplimiento de normativas globales y el endurecimiento del sistema hasta la preparación para amenazas emergentes, a continuación, exploramos algunas de las capas de defensa fundamentales integradas en RHEL.   SELinux: Control de Acceso Obligatorio por Defecto  La seguridad empresarial no consiste únicamente en cerrar puertos y aplicar parches, es una estrategia continua que debe abarcar el control de acceso, la integridad del software, la detección de intrusiones y la gestión proactiva de vulnerabilidades.   La primera línea de defensa es controlar estrictamente quién puede acceder a qué recursos y qué software puede ejecutarse, y no se puede hablar de seguridad en RHEL sin mencionar a SELinux (Security-Enhanced Linux), una herramienta de seguridad avanzada que viene activada por defecto en sistemas RHEL.   Aunque SELinux puede parecer una fuente de complicaciones especialmente cuando impide que aplicaciones personalizadas funcionen o bloquea el acceso a ciertas rutas o puertos, en realidad está haciendo su trabajo, aplicar un modelo de Control de Acceso Obligatorio (MAC). A diferencia del enfoque tradicional basado en permisos de archivos (DAC), SELinux define políticas estrictas y altamente granulares que controlan el comportamiento de usuarios, servicios y procesos. Utiliza etiquetas y tipos para decidir qué acciones están permitidas en archivos, carpetas y puertos, y cuáles no.   Tomemos el servicio web httpd como ejemplo práctico.   Por defecto:      El proceso httpd se ejecuta con el tipo SELinux httpd_t         El contenido en /var/www/html/ tiene la etiqueta httpd_sys_content_t, lo que permite que el servicio acceda a esos archivos.         Los puertos habituales como 80, 443, 8008 y 8443 están etiquetados como http_port_t, lo que autoriza a httpd a utilizarlos.      Supongamos que decidimos desplegar un sitio personalizado en /var/www/my_site y queremos servirlo desde el puerto 4449, en ese momento, SELinux va a bloquear la operación. ¿Por qué? Porque ni el directorio ni el puerto tienen las etiquetas adecuadas, para que httpd pueda operar correctamente, debemos etiquetar el nuevo directorio con httpd_sys_content_t y asociar el puerto 4449 con el tipo http_port_t.   Este tipo de intervenciones son comunes cuando se trabaja con aplicaciones personalizadas, y lejos de ser una molestia, representan una oportunidad para reforzar la seguridad, asegurándonos de que nada fuera de lo previsto pueda ejecutarse sin autorización explícita.   Afortunadamente, RHEL ofrece herramientas para facilitar este proceso. Por ejemplo, existe un rol de sistema específico para SELinux en Ansible, que permite automatizar la verificación y asignación de etiquetas de forma sencilla y repetible, ideal para despliegues a gran escala o entornos CI/CD, estos son algunos ejemplos del rol rhel-system-roles.selinux.         ### AIDE: Monitorización de la Integridad del Sistema   Mientras SELinux proporciona una defensa proactiva al prevenir acciones no autorizadas, una estrategia completa también necesita detectar cambios que ya han ocurrido, aquí es donde la monitorización de la integridad de archivos se vuelve crucial, uno de los métodos más comunes utilizados por atacantes consiste en modificar archivos o procesos ya existentes dentro del sistema, inyectando código malicioso o alterando configuraciones críticas. Este tipo de cambios, muchas veces sutiles, pueden abrir la puerta a vulnerabilidades graves o ser el inicio de un ataque más amplio.   Para enfrentar este riesgo, RHEL incluye AIDE (Advanced Intrusion Detection Environment), una herramienta que actúa como un sistema de monitoreo de integridad. Su función principal es detectar cualquier cambio no autorizado en los archivos del sistema, lo hace manteniendo una base de datos con el estado esperado de cada archivo y directorio, y comparándola con el estado actual del sistema, así, si se añade, borra, modifica o mueve un archivo, AIDE lo reportará.   Se necesita crear una base de datos inicial que represente el estado actual del sistema      Esto generará un archivo con el nombre /var/lib/aide/aide.db.new.gz, esta base de datos contiene hashes y metadatos de los archivos escaneados. En una instalación típica puede incluir más de 50.000 entradas.   Para empezar a usar esta base como referencia para futuros chequeos, simplemente se renombra a aide.db.gz, lo podemos hacer escribiendo en la terminal sudo mv /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz   Con AIDE ya configurado, puedes comenzar a detectar cambios en el sistema en cualquier momento ejecutando aide –-check, puedes configurar en /etc/aide.conf los cambios que quieres que detecte.   En caso de encontrar diferencias entre la base de datos y el sistema actual, AIDE informará detalladamente. En este ejemplo creo un archivo dentro del directorio /root llamado test-aide-demo, al analizar la base de datos automáticamente detecta los cambios e informa.      Esto puede indicar que un archivo fue modificado, agregado o incluso solo accedido.   Esto garantiza que cualquier cambio inesperado en el sistema pueda ser detectado rápidamente, permitiendo tomar acciones antes de que se conviertan en una brecha de seguridad.   Red Hat Insights: Seguridad Predictiva y a Escala   Mientras que herramientas como SELinux y AIDE aseguran la integridad de un sistema individual, el verdadero desafío empresarial es aplicar esta disciplina a escala. ¿Cómo garantizamos que cientos o miles de sistemas no solo estén protegidos, sino que cumplan con normativas y respondan a las amenazas de forma unificada? Aquí es donde la estrategia de Red Hat escala con Red Hat Insights.   Imaginate un analista de sistemas experto revisando incansablemente cada uno de sus sistemas RHEL, 24/7, este analista no solo detecta problemas, sino que predice fallos y entrega la solución exacta, a menudo como un script de automatización listo para usar, eso es, en esencia, Red Hat Insights   Es un servicio SaaS (Software como Servicio) que se conecta de forma segura a tu entorno RHEL, ya sea on-premise, en la nube pública o en un entorno híbrido, recopila datos anónimos de configuración y telemetría, los compara con una knowledge base masiva curada por los ingenieros de Red Hat y te devuelve recomendaciones personalizadas y priorizadas. Veamos cómo transforma los desafíos diarios en tareas manejables.   No se limita a detectar problemas de seguridad los entiende y te ayuda a resolverlos, su servicio de Vulnerability va mucho más allá de mostrar una lista de CVEs. Por cada vulnerabilidad encontrada, te ofrece contexto claro y útil, qué sistemas están afectados, qué tan grave es (según el estándar CVSS), y lo más importante, si ya existe un exploit conocido que podría ser usado por atacantes, además, guía paso a paso hacia la solución, indicando exactamente qué actualización aplicar o qué recurso técnico consultar para resolver la vulnerabilidad.   Y aquí es donde pasa de ser una herramienta de análisis a una de acción si una vulnerabilidad crítica afecta a decenas o cientos de servidores, corregirla uno por uno sería lento, complicado y con riesgo de error. Insights automatiza ese proceso generando, con un solo clic, un Playbook personalizado. Este no es un guion genérico, sino un conjunto de instrucciones precisas para aplicar solo en los sistemas que tú elijas, con las tareas exactas para solucionar la vulnerabilidad.      Es importante destacar que Red Hat Insights es una plataforma multifacética que va mucho más allá de la seguridad, sus servicios también abarcan la gestión proactiva del cumplimiento (Compliance), la optimización del rendimiento y la estabilidad (Advisor) y el análisis de la configuración, sin embargo, en esta ocasión, únicamente mencionamos Vulnerability, ya que aborda de manera directa el dilema del volumen de CVEs y la necesidad de una gestión basada en el riesgo real.   Red Hat Ansible Automation Platform: Automatización como Defensa   Tener un plan de remediación automatizado es solo la mitad de la batalla. ¿Cómo se ejecuta ese plan de forma segura, controlada y auditable en toda la empresa? Aquí es donde entra Red Hat Ansible Automation Platform (AAP)   Ansible proporciona un lenguaje común y un motor de automatización unificado que permite a los equipos de seguridad orquestar acciones a través de múltiples productos y proveedores. Transforma tareas complejas y manuales en playbooks simples, legibles por humanos y reutilizables, esto no solo acelera drásticamente la respuesta a incidentes, sino que también fomenta una cultura de colaboración, donde tanto los analistas de seguridad como los operadores de TI pueden entender, verificar y ejecutar las mismas automatizaciones.   Orquestación del Firewall: De la Detección a la Contención   El firewall de una organización es su portero digital, el guardián que decide qué tráfico entra y sale de la red, gestionar sus reglas es una de las tareas más críticas y, a menudo, más tediosas, en un entorno empresarial típico, esto implica interactuar con soluciones de proveedores como Check Point, Palo Alto Networks, Fortinet, y otros, cada uno tiene su propia API y su propia lógica. A través de roles y colecciones de contenido certificado, AAP facilita la interacción con distintos proveedores sin necesidad de adaptarse a cada interfaz o API específica.      Consideremos un escenario de respuesta a incidentes clásico, un sistema de monitorización detecta un comportamiento sospechoso proveniente de una dirección IP externa. El análisis confirma que se trata de un intento de ataque. La necesidad es inmediata, bloquear esa IP en el firewall perimetral para detener la amenaza en seco.   En un flujo de trabajo tradicional, este sería un proceso manual. Con Ansible, se convierte en una acción instantánea y automatizada. Utilizando el rol ansible_security.acl_manager, un analista puede ejecutar un playbook preaprobado y extraordinariamente simple. Este playbook no requiere conocimientos profundos de la sintaxis específica del firewall simplemente define la intención, se especifican variables claras y concisas como la IP de origen a bloquear, la IP de destino que se está protegiendo, y el tipo de sistema      Al ejecutar este playbook, Ansible se conecta a la API del servidor de gestión de Check Point y traduce esta simple intención en las acciones necesarias para crear y aplicar una nueva regla de seguridad, en segundos, la IP del atacante es bloqueada, la amenaza se contiene, y todo el proceso queda registrado y es auditable.   La misma lógica se aplica a la inversa, una vez que el incidente ha sido investigado y resuelto, la misma acl_manager puede ser utilizada con una tarea de unblock_ip para eliminar la regla, asegurando que los bloqueos temporales no se conviertan en problemas operativos permanentes. Esta capacidad de gestionar el ciclo de vida completo de una regla de firewall de forma programática, rápida y consistente es un cambio fundamental para cualquier equipo de seguridad   Gestión de IDPS: Despliegue de Reglas a Escala   Si el firewall es ‘el portero’, el Sistema de Detección y Prevención de Intrusiones (IDPS) es el perro guardián que patrulla constantemente la red, buscando patrones de comportamiento malicioso. Herramientas como Snort son increíblemente potentes, pero su eficacia depende enteramente de la calidad y actualidad de sus reglas, cuando surge una nueva amenaza o se descubre una nueva técnica de ataque, es crucial desplegar una nueva firma de detección en todos los sensores de IDPS de la organización de manera rápida y uniforme.   Aquí, de nuevo, el proceso manual es un cuello de botella, iniciar sesión en cada servidor de Snort para editar manualmente los archivos de reglas es lento, propenso a errores de copia y pega, y difícil de escalar, a través de roles como ansible_security.ids_rule, los equipos pueden gestionar las firmas de Snort como si fueran código.   Imaginemos que el equipo de seguridad descubre un nuevo tipo de ataque que intenta acceder al archivo /etc/passwd a través de peticiones web, se necesita una regla para detectar este patrón de inmediato, en lugar de enviar un correo electrónico con instrucciones, se crea un playbook.   Este playbook es un ejemplo de claridad y potencia, primero, se asegura de que la automatización se ejecute con los privilegios necesarios en el servidor Snort (become: true). Luego, especifica el proveedor (ids_provider: snort). La parte más importante es la propia regla, definida en la variable ids_rule en la sintaxis nativa de Snort, pero gestionada y desplegada por Ansible. El playbook también indica exactamente dónde debe escribirse la regla (ids_rules_file) y que su estado debe ser presente, es decir, que se cree si no existe.      Con la ejecución de ansible-navigator, este playbook se conecta a todos los servidores Snort definidos en el inventario y añade la nueva regla de forma atómica y consistente. La verificación es tan simple como conectarse a uno de los servidores y comprobar que la nueva línea ha sido añadida al final del archivo de reglas.   Los ejemplos de gestión de firewalls y IDPS son potentes por sí solos, pero su verdadero valor transformador se revela cuando se combinan en flujos de trabajo de seguridad orquestados. Ansible Automation Platform no solo ejecuta tareas aisladas, permite construir una respuesta a incidentes coherente y de múltiples pasos que se ejecuta a la velocidad de la máquina, no a la velocidad humana.   Este nivel de automatización reduce el tiempo medio de respuesta (MTTR) de horas a meros segundos. Libera a los analistas de seguridad de tareas repetitivas y les permite centrarse en actividades de mayor valor, como la caza de amenazas y el análisis estratégico   Red Hat OpenShift: Seguridad en la Cadena de Suministro de Software   Hemos asegurado el sistema operativo y automatizado su gestión, pero las aplicaciones modernas ya no viven ahí, hoy se ejecutan en contenedores y se despliegan en nubes híbridas, por eso, la estrategia de seguridad de Red Hat se extiende naturalmente a esta capa con ‘Red Hat OpenShift’.   En este apartado, nos enfocaremos en un aspecto clave de esa seguridad, la protección de la cadena de suministro de software (software supply chain). No cubriremos toda la seguridad de OpenShift, sino cómo garantizar que, desde la construcción hasta el despliegue, las aplicaciones sean legítimas, confiables y seguras.   Construyendo una Cadena de Suministro Confiable   El incidente XZ backdoor fue una llamada de atención global, la seguridad no puede empezar en el servidor de producción, sino desde el origen mismo del software, para el mundo de los contenedores, esto significa proteger toda la cadena de suministro, desde la construcción de la imagen hasta su despliegue final.   Construir una cadena de suministro segura y confiable requiere cuidar cada etapa del ciclo de vida del software, desde la escritura del código hasta su puesta en producción.   Todo comienza con la elección de una imagen base. Hoy existen miles de imágenes en repositorios públicos, pero no todas ofrecen el mismo nivel de calidad, mantenimiento o seguridad. Por eso, es responsabilidad de cada equipo elegir cuidadosamente.      Muchas organizaciones prefieren partir de una imagen base mínima, confiable y mantenida, como las Red Hat Universal Base Images (UBI), estas contienen solo lo esencial, lo que permite mantener el control total para aplicar parches rápido y reducir la superficie de ataque, agregando solo los frameworks y librerías que la aplicación necesita.   Pero, aunque una aplicación pase todas las pruebas de seguridad y funcione perfectamente, ¿cómo estar seguros de que realmente fue construida con nuestro código legítimo? Un atacante podría haber insertado código malicioso que robe información sin alterar el comportamiento visible.   Antes, documentos físicos se protegían con sellos que garantizaban su integridad. Hoy, esa función la cumplen las firmas criptográficas.   Firmar digitalmente el código fuente es un primer paso fundamental. Cada cambio debe llevar una firma que confirme la identidad del autor y asegure que el código no fue alterado. Las pipelines de CI/CD deben rechazar automáticamente cualquier commit sin firma válida.   Del mismo modo, las imágenes de contenedor deben firmarse en el momento de su creación, para asegurar que provienen de una fuente confiable y no han sido modificadas. Plataformas como OpenShift pueden validar estas firmas antes del despliegue, permitiendo solo la ejecución de imágenes autorizadas.      Escaneo Continuo y SBOM: Visibilidad y Control   Incluso siguiendo estas mejores prácticas, el riesgo de vulnerabilidades persiste, estas pueden venir desde la imagen base o surgir durante la construcción de la aplicación.   Por eso, es crucial escanear las imágenes en distintos puntos, revisar periódicamente las imágenes base y, si se detecta alguna vulnerabilidad, reconstruirlas y actualizarlas, además, escanear cada nueva imagen antes de pasarla a producción, bloqueando cualquier imagen con fallas críticas para devolverla al equipo de desarrollo.   Para tener visibilidad total sobre los componentes que integran una imagen, es fundamental generar un Software Bill of Materials (SBOM), que documenta todas las librerías, frameworks y dependencias, facilitando auditorías y evaluaciones de riesgo. Este inventario debe generarse y almacenarse junto con la imagen en el registro de contenedores.   La Solución Integrada: Red Hat Trusted Software Supply Chain   Para enfrentar todos estos desafíos, Red Hat ofrece la Red Hat Trusted Software Supply Chain, una colección de soluciones integradas que incorporan seguridad en cada etapa del ciclo de vida de las aplicaciones nativas de la nube.      En lugar de que los equipos deban armar y asegurar por su cuenta una cadena de herramientas y componentes dispares, Red Hat entrega una plataforma completa, fácil de usar y cohesiva, que conecta todo de forma segura y confiable.   La plataforma integra un conjunto de herramientas diseñadas para cubrir todo el ciclo de vida del software, desde el desarrollo hasta la producción, asegurando agilidad y confianza en cada etapa. Para la fase de desarrollo, Red Hat Developer Hub actúa como un portal centralizado que simplifica la creación de aplicaciones, permitiendo a los equipos enfocarse en el código en lugar de la complejidad de la infraestructura. Este proceso se construye sobre las Universal Base Images, que ofrecen un cimiento fiable y seguro para minimizar riesgos desde el inicio.   Para asegurar la cadena de suministro, Trusted Artefact Signer aplica una firma digital al software para validar su autenticidad. A su vez, Trusted Profile Analyzer evalúa de forma inteligente las dependencias para identificar solo las vulnerabilidades que suponen un riesgo real. La gestión de estas imágenes se centraliza en Quay, un registro que las almacena de forma segura y las analiza continuamente en busca de amenazas.   Finalmente, OpenShift actúa como el motor de orquestación que automatiza el despliegue y la gestión de las aplicaciones, mientras que Advanced Cluster Security añade una capa de protección en tiempo de ejecución, monitoreando el entorno y garantizando el cumplimiento de las políticas de seguridad.   Con esta oferta, Red Hat acompaña a los equipos para construir, verificar y desplegar software seguro y confiable, desde el primer código hasta la aplicación en producción.   Conclusiones y Reflexiones Finales   El modelo open source, por su naturaleza transparente, tiende a reportar más vulnerabilidades que el software propietario, lo cual no significa que sea menos seguro, sino que permite un análisis más honesto y riguroso del riesgo real. En lugar de dejarnos llevar por el número de CVEs publicados, debemos cambiar el foco hacia la verdadera prioridad, entender qué vulnerabilidades representan un riesgo real y cuáles no. Este enfoque basado en el riesgo y no en la cantidad es indispensable en un mundo donde la estrategia de parches tradicional ya no es suficiente.   Red Hat demuestra que no basta con consumir software libre, sino que se requiere un enfoque proactivo y estructurado para convertirlo en una verdadera plataforma empresarial segura. Herramientas como las que hemos hablado aquí, permiten construir una defensa integral que abarca desde el control de accesos, hasta la seguridad en entornos de contenedores. Todo esto bajo una misma visión coherente, donde la protección se integra desde la creación del software hasta su despliegue.  ","categories": ["Seguridad","Red Hat","Open Source"],
        "tags": ["RHEL","SELinux","Ansible","OpenShift","CVE","Seguridad Empresarial"],
        "url": "/seguridad/red%20hat/open%20source/Seguridad-empresarial-con-red-hat/",
        "teaser": null
      },{
        "title": "Red Hat Ansible Automation Platform 2.5: Guía de Instalación en RHEL 10 (Topología Growth Contenerizada)",
        "excerpt":"Red Hat Ansible Automation Platform 2.5: Tu Guía Práctica de Instalación en RHEL 10 (Topología Growth Contenerizada)   Introducción   Esta guía sirve para ver el proceso de instalación de Red Hat Ansible Automation Platform (AAP) 2.5 en un entorno Red Hat Enterprise Linux (RHEL) 10. El objetivo es instalar AAP utilizando una topología “Growth” contenerizada, lo que significa que todos los componentes se instalarán en una única máquina virtual.   Esta configuración es perfecta para desarrolladores, para realizar pruebas o para pequeñas implementaciones donde estás comenzando a explorar el poder de la automatización con AAP. Además, lo mejor de esta topología es su flexibilidad, se podrá escalar a una arquitectura “Enterprise” más compleja, con alta disponibilidad y recursos distribuidos.   En este artículo, revisaremos los requisitos previos del sistema, la configuración esencial del entorno y los componentes clave de AAP, para tener una base sólida antes de empezar la instalación paso a paso.   Entendiendo Ansible Automation Platform (AAP)   Antes de meternos de lleno en los detalles técnicos, es fundamental entender qué es exactamente Ansible Automation Platform y por qué se ha convertido en una herramienta tan valiosa.   Para situarnos mejor, vamos a entender conceptos:      Ansible: el motor de automatización, la herramienta base que permite definir y ejecutar tareas en servidores y sistemas.   AWX: el proyecto open source que añade una interfaz gráfica y servicios básicos para gestionar Ansible de forma más cómoda.   AAP (Ansible Automation Platform): la versión empresarial respaldada por Red Hat, que parte de AWX y lo expande con seguridad, soporte oficial y funcionalidades avanzadas para producción y grandes organizaciones.   Imagina que tienes que realizar la misma tarea repetidamente en decenas, o incluso cientos, de servidores o sistemas. Suena aburrido y un palo…, Ansible nació para resolver ese problema, permite escribir instrucciones que tus sistemas pueden ejecutar por ti, como, por ejemplo: “instalar un servidor web Apache en todos mis servidores Linux”. Pues bien, AAP eleva esta capacidad a un nivel empresarial.   Piensa en AAP como la versión corporativa y robusta de AWX, el proyecto de código abierto y gratuito de Ansible. Mientras que AWX es fantástico para experimentar y familiarizarte con la interfaz y los conceptos de automatización, AAP añade capas críticas de seguridad, un soporte oficial de Red Hat inestimable, y herramientas avanzadas para gestionar entornos de gran escala con total confianza. No se limita a ejecutar comandos; AAP te ayuda a orquestar procesos complejos, centralizar inventarios y credenciales, y facilitar el trabajo en equipo a través de una interfaz gráfica intuitiva.   Muchas organizaciones empiezan con AWX para probar las aguas, pero cuando la automatización se convierte en un pilar fundamental de sus operaciones, necesitan una plataforma estable, respaldada y con funcionalidades avanzadas. Ahí es precisamente donde brilla AAP, incluyendo componentes como Automation Controller, Execution Environments, Automation Mesh, acceso a contenido validado, parches de seguridad y, crucialmente, el soporte oficial de Red Hat.   Topologías y Métodos de Instalación   Cuando instalas Ansible Automation Platform, la forma en que decides organizar tu infraestructura se conoce como “topología”. Esto define cómo se distribuyen los diferentes componentes de AAP en tus servidores y cómo se interconectan para asegurar un rendimiento óptimo y una operación estable.   Red Hat valida y recomienda ciertas topologías de despliegue para asegurar que la plataforma funcione de manera fiable y con soporte completo:      Topología Enterprise: Diseñada para organizaciones grandes o entornos de producción críticos. Se enfoca en alta disponibilidad, máximo rendimiento y escalabilidad para manejar grandes volúmenes de usuarios y cargas de trabajo sin interrupciones.   Topología Growth: Ideal para organizaciones más pequeñas, entornos de desarrollo o con recursos limitados. Permite un despliegue más simple y económico al principio, con la flexibilidad de crecer y escalar a medida que tus necesidades evolucionan.   Es importante recordar que, si bien puedes instalar AAP en otras configuraciones, Red Hat solo garantiza soporte completo para las topologías que ellos mismos han probado y publicado. Utilizar una topología validada asegura que tu plataforma sea estable y confiable a largo plazo.   Existen tres métodos principales para instalar y desplegar Ansible Automation Platform 2.5, dependiendo de tu infraestructura y tus preferencias de gestión. Para esta guía, nos centraremos en el método “Contenedores” y la topología “Growth”.                  Método       Infraestructura       Descripción       Topologías probadas                       RPM       Máquinas virtuales y servidores físicos       El instalador RPM despliega AAP en Red Hat Enterprise Linux utilizando paquetes RPM. El cliente gestiona el ciclo de vida del producto e infraestructura.       RPM growth topology, RPM enterprise topology                 Contenedores       Máquinas virtuales y servidores físicos       El instalador basado en contenedores utiliza Podman para ejecutar AAP en contenedores sobre RHEL. El cliente gestiona el ciclo de vida del producto e infraestructura.       Container growth topology, Container enterprise topology                 Operator       Red Hat OpenShift       El operador despliega AAP dentro de OpenShift usando Red Hat OpenShift Operators. El cliente gestiona el ciclo de vida del producto e infraestructura.       Operator growth topology, Operator enterprise topology           Componentes   Para armar el “rompecabezas” de Ansible Automation Platform, es crucial conocer las piezas que lo componen. AAP no es solo una herramienta, sino un ecosistema de servicios interconectados que trabajan juntos para potenciar tu automatización.   Los componentes más importantes que debemos conocer, basándome en la documentación oficial de Red Hat:                  Componente       Descripción       ¿Por qué importa?                       Platform Gateway       La puerta de entrada a AAP. Maneja autenticación, permisos y guarda un registro de cambios (activity stream).       Te logueas una sola vez y accedes a todo. Además, tienes trazabilidad de lo que pasa.                 Automation Controller       El cerebro de la plataforma. Define, ejecuta y escala automatizaciones.       Permite orquestar playbooks desde lo simple hasta lo empresarial.                 Automation Hub       El “mercado central” de colecciones certificadas por Red Hat y partners.       Usas contenido probado y soportado, sin reinventar la rueda.                 Private Automation Hub       Tu propio hub privado y desconectado. Sincroniza contenido y guarda colecciones personalizadas.       Ideal para entornos on-premise o integrados con CI/CD.                 High Availability Hub       Una versión redundante y escalable del hub con múltiples nodos.       Alta disponibilidad = menos caídas y más tranquilidad.                 Event-Driven Ansible Controller       Automatización reactiva: escucha eventos y ejecuta acciones con rulebooks.       Aumenta la agilidad y automatiza decisiones en tiempo real.                 Automation Mesh       Una red de nodos distribuida que reparte la carga de trabajo.       Escalabilidad, resiliencia y flexibilidad en entornos grandes o dispersos.                 Execution Environments       Contenedores donde se ejecutan los playbooks. Incluyen motor + módulos.       Portabilidad y consistencia: “si funciona aquí, funciona en todos lados”.                 Ansible Galaxy       Comunidad para compartir roles y colecciones.       Reutilizas contenido y aceleras tus proyectos.                 Content Navigator       Interfaz de texto (TUI) y CLI principal para construir y ejecutar automatizaciones.       Tu navaja suiza en la terminal, base de futuros IDEs.                 PostgreSQL       Base de datos relacional donde se guarda todo: inventarios, credenciales, historial.       La memoria de la plataforma.           Detalles Técnicos   Esta sección se enfoca en los requisitos validados por Red Hat para una instalación “Growth” contenerizada. Aquí muestro el diseño y las especificaciones para desplegar AAP en una única máquina virtual, de forma clara y sencilla.   Virtual machine requirements   Estos son los requisitos mínimos de hardware para tu VM de RHEL 10 en una topología “Growth”:                  Requirement       Minimum requirement                       RAM       16 GB                 CPUs       4                 Local disk       Total available disk space: 60 GB Installation directory: 15 GB (if on a dedicated partition) /var/tmp for online installations: 1 GB /var/tmp for offline or bundled installations: 3 GB Temporary directory (defaults to /tmp) for offline or bundled installations: 10GB                 Disk IOPS       3000           System configuration   Estos son los aspectos clave que tu sistema RHEL 10 debe cumplir. Atención a la suscripción, ya que es un paso que a menudo se pasa por alto y puede causar problemas:                  Tipo       Descripción       Notas                       Suscripción       Suscripción válida de Red Hat Ansible Automation Platform Suscripción válida de Red Hat Enterprise Linux (para poder usar los repositorios BaseOS y AppStream)                         Sistema operativo       Red Hat Enterprise Linux 9.2 o versiones posteriores de Red Hat Enterprise Linux 9. Red Hat Enterprise Linux 10 o versiones posteriores de Red Hat Enterprise Linux 10.       —                 Arquitectura de CPU       x86_64, AArch64, s390x (IBM Z), ppc64le (IBM Power)       —                 ansible-core       RHEL 9: el programa de instalación usa ansible-core 2.14; la operación de Ansible Automation Platform usa ansible-core 2.16. RHEL 10: el programa de instalación y la operación de Ansible Automation Platform usan ansible-core 2.16.       El programa de instalación utiliza el paquete ansible-core del repositorio AppStream de RHEL. Ansible Automation Platform incluye ansible-core 2.16 para su operación, por lo que no es necesario instalarlo manualmente.                 Navegador       Una versión actualmente soportada de Mozilla Firefox o Google Chrome       —                 Base de datos       PostgreSQL 15       Las bases de datos externas (soporte por el cliente) requieren soporte ICU.           Network ports and protocols   A continuación, se listan los puertos de red y protocolos que AAP utiliza para la comunicación entre sus componentes. Es crucial que estos puertos estén abiertos en el firewall para asegurar la correcta operación de la plataforma:                  Port number       Protocol       Service       Source       Destination                       80/443       TCP       HTTP/HTTPS       Event-Driven Ansible       Automation hub                 80/443       TCP       HTTP/HTTPS       Event-Driven Ansible       Automation controller                 80/443       TCP       HTTP/HTTPS       Automation controller       Automation hub                 80/443       TCP       HTTP/HTTPS       Platform gateway       Automation controller                 80/443       TCP       HTTP/HTTPS       Platform gateway       Automation hub                 80/443       TCP       HTTP/HTTPS       Platform gateway       Event-Driven Ansible                 5432       TCP       PostgreSQL       Event-Driven Ansible       External database                 5432       TCP       PostgreSQL       Platform gateway       External database                 5432       TCP       PostgreSQL       Automation hub       External database                 5432       TCP       PostgreSQL       Automation controller       External database                 6379       TCP       Redis       Event-Driven Ansible       Redis container                 6379       TCP       Redis       Platform gateway       Redis container                 8443       TCP       HTTPS       Platform gateway       Platform gateway                 27199       TCP       Receptor       Automation controller       Execution container           PRACTICA - Instalación de Ansible Automation Platform   La instalación de Ansible Automation Platform requiere una serie de pasos preparatorios para asegurar un despliegue sin problemas. Nos centraremos en una instalación “Growth” contenerizada en RHEL 10.   Preparación del Sistema Operativo   Configuración del Usuario y Privilegios Sudo   Para la instalación, el usuario que ejecuta el instalador debe tener permisos para elevar privilegios a root sin necesidad de introducir una contraseña. Esto es fundamental, ya que muchos pasos del proceso requieren modificar servicios, paquetes y configuraciones críticas del sistema.   Para configurar esto, editamos el archivo sudoers (lo recomendado es crear un archivo nuevo en /etc/sudoers.d/user, esto es un ejemplo) y añadir una línea similar a la siguiente, sustituyendo user por el nombre de tu usuario:   user ALL=(ALL) NOPASSWD: ALL     Esto permite a user ejecutar comandos como root con sudo sin pedir contraseña.   Verificación del Nombre de Host (FQDN)   Es crucial que el nombre de host del servidor esté configurado como un Nombre de Dominio Completamente Cualificado (FQDN). Esto asegura una comunicación adecuada entre los servicios de AAP.   Podemos verificarlo con el siguiente comando:   hostname -f     Si no devuelve un FQDN, debemos configurarlo en nuestro sistema RHEL.   Gestión de Suscripciones y Repositorios   Para acceder a los paquetes y contenedores de Red Hat, el servidor RHEL debe estar correctamente suscrito y los repositorios necesarios deben estar habilitados.   Nos aseguramos de que el sistema está suscrito a Red Hat y que tiene acceso a los repositorios BaseOS y AppStream. Podemos comprobar el estado de la suscripción con:   sudo subscription-manager status     Si no está suscrito, podemos registrarlo con:   sudo subscription-manager register   Es necesario que los repositorios de AppStream y BaseOS estén habilitados, para ello verificamos que los tenemos activos. Aquí tenemos una imagen que muestra cómo verificar los repositorios activos:      Siguiente paso, instalamos el paquete ansible-core, que el instalador de AAP utilizará.  sudo dnf install ansible-core -y     Y opcionalmente podemos instalar los paquetes wget, git-core, rsync y vim que nos pueden ser útiles durante la instalación:   sudo dnf install wget git-core rsync vim -y   Descarga del Instalador de Ansible Automation Platform   Visitamos el portal de descargas de Ansible Automation Platform. Desde allí es posible obtener las versiones más recientes del instalador.   Existen dos modalidades principales de instalación:      Instalación Online: Selecciona la opción “Ansible Automation Platform 2.5 Containerized Setup”. En este caso, durante el proceso de instalación, el instalador descargará los contenedores necesarios directamente desde los repositorios de Red Hat.   Instalación Offline (paquete completo): Selecciona la opción “Ansible Automation Platform 2.5 Containerized Setup Bundle”. Este paquete incluye todos los artefactos requeridos para entornos aislados de Internet o con restricciones de red.   Nosotros para esta guía elegiremos la online, una vez elegida la modalidad, descargamos el archivo .tar.gz correspondiente a la versión y arquitectura del sistema.   Aquí tenemos una imagen que ilustra la descarga desde el portal:      Los archivos descargados deben copiarse a la máquina donde se realizará la instalación. Esto suele hacerse desde la estación de administración hacia el servidor RHEL destino.   La forma más segura de realizar esta transferencia es mediante SCP (Secure Copy Protocol).   En el servidor RHEL, tendremos que definir un directorio que servirá como punto de instalación.   Requisito importante: debemos asegurarnos de contar con al menos 15 GB de espacio libre en el directorio seleccionado, ya que la instalación inicial genera múltiples contenedores y datos temporales.   En este caso utilizaremos /home/user/demos para descomprimir el archivo tar:   mkdir -p /home/user/demos   df -h /home/user/demos     Con los archivos ya presentes en el servidor, vamos a descomprimir el instalador en el directorio demos.   tar -xvzf ansible-automation-platform-setup-2.5-containerized-tar.gz -C /home/user/demos     Al finalizar, se creará un directorio con todos los archivos y scripts necesarios para continuar con el despliegue de la plataforma.   Configuración del Archivo de Inventario      Cuando instalamos Ansible Automation Platform (AAP), todo gira en torno a un archivo llamado inventory. Este archivo es como el “mapa” que le dice al instalador qué componentes debe desplegar, en qué servidores y con qué configuraciones.   Sin este archivo, el instalador no sabe qué hacer, así que aquí te explico cómo funciona y cómo puedes adaptarlo a tu entorno.   Dentro del paquete de instalación que hemos descargado vienen ejemplos de inventario:      inventory: pensado para instalaciones enterprise (distribuidas, con varios nodos).   inventory-growth: pensado para instalaciones all-in-one (todo en un mismo servidor).      La topología que queremos implementar es la growth, vamos a modificar el inventory-growth para que se ajuste a nuestra configuración.   Para ello abrimos el archivo y añadimos nuestro fqdn y credenciales de Red Hat en los campos necesarios. El archivo se verá similar a este:   # This is the AAP installer inventory file intended for the Container growth deployment topology.   # This inventory file expects to be run from the host where AAP will be installed.   # Please consult the Ansible Automation Platform product documentation about this topology's tested hardware configuration.   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/tested_deployment_models/container-topologies   #   # Please consult the docs if you're unsure what to add   # For all optional variables please consult the included README.md   # or the Ansible Automation Platform documentation:   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation     # This section is for your AAP Gateway host(s)   # -----------------------------------------------------   [automationgateway]   your.fqdn.here     # This section is for your AAP Controller host(s)   # -----------------------------------------------------   [automationcontroller]   your.fqdn.here     # This section is for your AAP Automation Hub host(s)   # -----------------------------------------------------   [automationhub]   your.fqdn.here     # This section is for your AAP EDA Controller host(s)   # -----------------------------------------------------   [automationeda]   your.fqdn.here     # This section is for the AAP database   # -----------------------------------------------------   [database]   your.fqdn.here     [all:vars]   # Ansible   ansible_connection=local     # Common variables   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#ref-general-inventory-variables   # -----------------------------------------------------   postgresql_admin_username=postgres   postgresql_admin_password=your_postgresql_admin_password     registry_username=your_rhn_username   registry_password=your_rhn_password     redis_mode=standalone     # AAP Gateway   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#ref-gateway-variables   # -----------------------------------------------------   gateway_admin_password=your_gateway_admin_password   gateway_pg_host=your.fqdn.here   gateway_pg_password=your_gateway_pg_password     # AAP Controller   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#ref-controller-variables   # -----------------------------------------------------   controller_admin_password=your_controller_admin_password   controller_pg_host=your.fqdn.here   controller_pg_password=your_controller_pg_password   controller_percent_memory_capacity=0.5     # AAP Automation Hub   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#ref-hub-variables   # -----------------------------------------------------   hub_admin_password=your_hub_admin_password   hub_pg_host=your.fqdn.here   hub_pg_password=your_hub_pg_password   hub_seed_collections=false     # AAP EDA Controller   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#event-driven-ansible-controller   # -----------------------------------------------------   eda_admin_password=your_eda_admin_password   eda_pg_host=your.fqdn.here   eda_pg_password=your_eda_pg_password    Sustituimos your.fqdn.here por el fqdn de nuestra instancia donde instalaremos el Ansible Automation Platform.   Modificamos el &lt;set your own&gt; por las contraseñas que queramos para nuestro usuario admin en cada componente que se indica en el inventario.   Y en los campos registry_username=your_rhn_username y registry_password=your_rhn_password indicamos nuestro usuario y contraseña de la cuenta de Red Hat.   Una vez lo tenemos todo listo podemos lanzar el instalador y indicar el archivo de inventario correspondiente (opción -i). Nos tenemos que assegurar de estar en el directorio donde descomprimimos el instalador (e.g., /home/user/demos/ansible-automation-platform-containerized-setup-2.5-19).   cd /home/user/demos/ansible-automation-platform-containerized-setup-2.5-19 ansible-playbook -i inventory-growth ansible.containerized_installer.install      Cuando finalice la instalación de Ansible Automation Platform (AAP), el siguiente paso es comprobar que la interfaz web esté disponible.   De manera predeterminada, podemos acceder escribiendo en el navegador:   https://&lt;gateway_node&gt;:443   Aquí reemplazar &lt;gateway_node&gt; por el nombre o la dirección IP del servidor donde desplegamos el Automation Gateway.   Para entrar al panel, utilizar el usuario admin (gateway_admin_username) y la contraseña que definiste en la instalación (gateway_admin_password).   Aquí tenemos una captura de pantalla de la pantalla de inicio de sesión de AAP:    Para habilitar el soporte completo y recibir actualizaciones, debemos activar la suscripción de Ansible Automation Platform. Dentro de la interfaz web, nos dirigimos a la sección de administración de suscripciones e introducimos nuestras credenciales de acceso de Red Hat (Client ID y Client Secret).      Finalmente, ya accedemos, ahora podemos empezar a explorar todas las capacidades de automatización que ofrece Ansible Automation Platform.      Mi idea con este artículo era desmitificar el proceso, compartir esa “receta” que a mí me ha funcionado bien para arrancar rápido con una topología “Growth”. Podemos pensar en ella como un campo de pruebas personal, donde podemos cacharrear, aprender y, lo más importante, empezar a ver lo que ofrece AAP sin el estrés de una configuración gigante y con una gran flexibilidad para crecer cuando nosotros queramos.  ","categories": ["Automation","Ansible","RedHat"],
        "tags": ["AAP","AnsibleAutomationPlatform","RHEL","InstallationGuide","Containerized"],
        "url": "/automation/ansible/redhat/AAP-Guia-de-instalacion-2.5/",
        "teaser": null
      },{
        "title": "Red Hat Enterprise Linux: Integración de RHEL 10 con Active Directory 2019 usando SSSD y realmd",
        "excerpt":"Integración de RHEL 10 con Active Directory 2019 usando SSSD y realmd   Introducción   La gestión centralizada de identidades y accesos es clave. Microsoft Active Directory (AD) se ha consolidado como el estándar en muchas infraestructuras para esta tarea.   En esta guía, desglosaremos las opciones de integración y veremos paso a paso cómo conectar un sistema RHEL a un dominio de Active Directory.   Opciones de Integración: ¿Cuál elegir?   Existen varias formas de lograr esta integración, cada una con sus particularidades. Aquí te presentamos las principales:   Tabla de opciones de integración                  Opción de Integración       Descripción Técnica                       System Security Services Daemon (SSSD)       Es el componente de autenticación y resolución de identidades más moderno y recomendado. Permite a RHEL integrarse de forma nativa con dominios Active Directory utilizando protocolos como Kerberos, LDAP y DNS. Ofrece funcionalidades avanzadas como caché de credenciales, resolución de grupos y usuarios, mapeo de atributos AD a NSS/PAM, y soporte para autenticación offline. SSSD actúa como un middleware entre las aplicaciones del sistema y las fuentes externas de identidad, centralizando la gestión de políticas y sesiones.                 Samba Winbind       Implementación basada en Samba que permite a los sistemas Linux funcionar como miembros de un dominio Windows/AD. Utiliza protocolos SMB/CIFS, NTLM y Kerberos, proporcionando resolución de usuarios y grupos de dominio a través de nsswitch y PAM. Aunque es funcional, su arquitectura basada en SMB puede implicar una mayor carga y dependencia del stack de Samba en comparación con SSSD.                 Managed Service Account (MSA)       Una característica de Active Directory que permite crear cuentas de servicio administradas. Diseñada para que aplicaciones o demonios específicos en RHEL se autentiquen contra AD de forma segura sin requerir la unión completa del host al dominio. Las MSA gestionan automáticamente la rotación de contraseñas y las políticas de autenticación mediante Kerberos, reduciendo la sobrecarga administrativa y los riesgos asociados a credenciales estáticas. Ideal para servicios, no para login de usuarios interactivos.           En esta guía, nos centraremos en el método más recomendado y versátil para una integración profunda: SSSD.   Descubriendo SSSD   El System Security Services Daemon (SSSD) es un servicio esencial en los sistemas Linux/UNIX que actúa como intermediario inteligente para la gestión de identidad y autenticación. Su propósito es conectar tu sistema local (el “cliente SSSD”) a diversas fuentes de identidad y mecanismos de autenticación remotos (los “proveedores”).   SSSD opera en dos etapas clave:      Conexión con el proveedor remoto: Se comunica con un proveedor remoto (LDAP, AD, Kerberos, IdM) para obtener información de identidad del usuario (UID, GID, etc.) y datos necesarios para autenticación.   Caché local de identidad y credenciales: Crea y mantiene una caché local de esta información, permitiendo autenticación offline y mejor rendimiento.   Gracias a esta arquitectura, los usuarios pueden autenticarse en Linux usando cuentas almacenadas en el proveedor remoto sin crear cuentas locales duplicadas. SSSD puede configurarse para crear directorios de inicio automáticamente.   Los Pilares de la Autenticación: PAM y NSS   SSSD obtiene la información de identidad desde un servidor remoto y la almacena localmente. ¿Cómo utiliza el sistema operativo esa información?   PAM (Pluggable Authentication Modules)      Función: Autenticación y autorización de usuarios.   Pregunta clave: “¿Puede este usuario autenticarse y acceder?”   NSS (Name Service Switch)      Función: Define de dónde obtener información sobre usuarios, grupos, hosts, contraseñas, etc.   Archivo de configuración: /etc/nsswitch.conf   passwd:     files ldap sss group:      files ldap sss shadow:     files ldap sss hosts:      files dns sss  Esto significa que, para passwd (usuarios), el sistema primero busca en /etc/passwd (files), luego en un servidor LDAP (ldap), y finalmente consulta a SSSD (sss).      Pregunta clave: “¿De dónde obtengo la información de este usuario (UID, GID, nombre)?”   Flujo de Autenticación Detallado      Requisitos y Opciones de Mapeo de IDs   Tipos de Servidores de Identidad Compatibles con SSSD   SSSD es altamente versátil y puede interactuar con diversas fuentes de identidad:                  Tipo de Servidor       Descripción                       Active Directory (AD)       Servicio de directorio de Microsoft que proporciona autenticación, autorización y políticas centralizadas, el foco de nuestro artículo.                 Identity Management (IdM) en RHEL       Implementación de gestión de identidades integrada en RHEL basada en FreeIPA, ideal para entornos Linux puros o híbridos compatibles con AD.                 Servidores genéricos LDAP o Kerberos       Sistemas de directorio o autenticación basados en estándares abiertos que proporcionan servicios de identidad sin la complejidad inherente de Active Directory o las características de IdM.           POSIX ID Mapping vs. POSIX Attributes   Cuando integramos Linux con Active Directory, nos enfrentamos a una diferencia fundamental: cómo manejan las identidades los usuarios.      Linux utiliza UID (User ID) y GID (Group ID), siguiendo el estándar POSIX.   Windows AD utiliza SID (Security ID), un identificador único globalmente.   Para que un usuario de Active Directory pueda acceder a un sistema Linux, necesitamos traducir o asignar esos identificadores de Windows (SID) a los de Linux (UID/GID).  Aquí es donde SSSD ofrece dos opciones principales:      POSIX ID Mapping   POSIX Attributes   POSIX ID Mapping (mapeo automático)      Esta es la opción predeterminada.   En este modo, SSSD genera automáticamente los UID y GID a partir del SID de cada usuario de AD mediante un algoritmo interno.   Así, no es necesario modificar nada dentro de Active Directory.   POSIX Attributes (atributos POSIX en AD)      En este modo, los UID y GID se definen directamente en Active Directory, utilizando los atributos POSIX estándar (como uidNumber, gidNumber, unixHomeDirectory, etc.).   SSSD simplemente lee esos valores cuando el usuario inicia sesión.   Requiere editar o extender el esquema de AD para incluir los atributos POSIX, y la configuración es más compleja.   ¡Demo! Integrando RHEL con Active Directory   En esta práctica, integraremos un sistema RHEL 10 a un dominio de Active Directory 2019 utilizando SSSD y el método de POSIX ID Mapping.   Utilizaremos un dominio ficticio para fines educativos: umbrella.corp.   El objetivo es permitir que los usuarios de Active Directory puedan autenticarse directamente en Linux con su nombre de usuario y contraseña de AD, sin necesidad de crear cuentas locales en RHEL.  Gracias a SSSD y POSIX ID Mapping, RHEL asignará automáticamente los UID y GID a los usuarios de AD, garantizando una identidad única dentro del sistema Linux sin modificar Active Directory.     Información de los Sistemas   RHEL 10.0                  Campo       Valor                       Hostname       leon                 IP       192.168.6.4                 Sistema Operativo       RHEL 10.0                 Rol       Servidor Linux a integrar con Active Directory                 Dominio       umbrella.corp                 DNS Primario       192.168.6.7                 Estado Integración AD       Pendiente                 Comentarios       Usará SSSD y realmd para unir al dominio             Windows Server 2019 (Active Directory / DNS)                  Campo       Valor                       Hostname       WIN-TURSKABH596                 IP       192.168.6.7                 Sistema Operativo       Windows Server 2019                 Rol       Controlador de Dominio / DNS                 Dominio       umbrella.corp                 DNS Primario       192.168.6.7                 Comentarios       Servidor principal del dominio, provee DNS interno                Nota:  El controlador de dominio también funciona como servidor DNS del dominio.  Esto es importante porque Active Directory depende del DNS para localizar controladores de dominio y otros servicios.  RHEL apunta a este DNS para poder resolver nombres dentro del dominio y autenticar usuarios correctamente.      Requisitos previos   Antes de empezar, hay que asegurarse de que el entorno tiene:      Conectividad de red Los puertos necesarios para la comunicación con AD deben estar abiertos.                  Servicio       Puerto       Protocolo       Notas                       DNS       53       UDP y TCP       —                 LDAP       389       UDP y TCP       —                 LDAPS       636       TCP       Opcional                 Samba       445       UDP y TCP       Para los Objetos de Directiva de Grupo (GPO)                 Kerberos       88       UDP y TCP       —                 Kerberos (kadmin)       464       UDP y TCP       Usado por kadmin para establecer y cambiar contraseñas                 Catálogo Global LDAP       3268       TCP       Si se usa la opción id_provider = ad                 Catálogo Global LDAPS       3269       TCP       Opcional                 NTP       123       UDP       Opcional                 NTP       323       UDP       Opcional                Configuración DNS   El servidor DNS de tu RHEL debe apuntar al controlador de dominio de Active Directory.  Puedes verificarlo en /etc/resolv.conf.            Sincronización de hora (NTP)   La hora del sistema RHEL debe estar sincronizada con el AD.  Esto es crítico para el correcto funcionamiento de Kerberos.        Empecemos con la instalación   Para empezar, instalamos los paquetes esenciales para la integración con Active Directory y el funcionamiento de SSSD:   sudo dnf install samba-common-tools realmd oddjob oddjob-mkhomedir sssd adcli krb5-workstation     Una vez instalados los paquetes, podemos usar realm discover para verificar la existencia y obtener información sobre nuestro dominio de Active Directory   realm discover ad.example.com      Es normal que el configured salga como no antes de unirse al dominio.   Antes de unir RHEL al dominio, es necesario ajustar las políticas criptográficas para soportar algunas configuraciones de Active Directory más antiguas   sudo update-crypto-policies --set DEFAULT:AD-SUPPORT-LEGACY      Se recomienda hacer un reboot para que se apliquen las politicas, es necessario reiniciar los servicios para que se aplique y con el reboot se inician todos de nuevo…   Esto permite que el sistema Linux utilice algoritmos y protocolos de cifrado compatibles con versiones de Active Directory que aún no soportan las políticas criptográficas más estrictas de RHEL 10 por defecto. Si no se aplica este ajuste, el intento de unir el dominio (realm join) puede fallar debido a incompatibilidades de cifrado o autenticación.   Ahora, el paso crucial, unir el sistema RHEL al dominio de Active Directory. El comando realm join no solo une el equipo, sino que también configura SSSD automáticamente con los parámetros adecuados. Te pedirá la contraseña de un usuario con permisos para unir equipos al dominio (por ejemplo, el usuario Administrator de AD).   sudo realm join ad.example.com -v       Para comprobar que la integración ha sido exitosa y que los usuarios de Active Directory son reconocidos en RHEL, podemos usar el comando getent passwd con un usuario de AD.   getent passwd administrator@ad.example.com     Ahora RHEL ja está integrado con Active Directory. Cualquier usuario de AD puede iniciar sesión en RHEL utilizando las credenciales de dominio  ","categories": ["RedHat","ActiveDirectory"],
        "tags": ["RHEL","ActiveDirectory","SSSD"],
        "url": "/redhat/activedirectory/RHEL-Integracion-RHEL-10-con-AD/",
        "teaser": null
      },{
        "title": "Red Hat Ansible Automation Platform 2.6: Guía de Integración con Active Directory (LDAP/LDAPS)",
        "excerpt":"Introducción   El propósito de este documento es mostrar cómo integrar Ansible Automation Platform (AAP) con Active Directory mediante el protocolo LDAP o LDAPS, permitiendo que los usuarios del dominio puedan autenticarse directamente con sus credenciales corporativas. Con esta configuración, los usuarios del dominio podrán iniciar sesión directamente en AAP con sus credenciales, sin que el sistema almacene contraseñas locales.   AAP delega la autenticación a AD a través de consultas LDAP/LDAPS, lo que permite una gestión segura y centralizada de usuarios, grupos y permisos.   Arquitectura de autenticación en AAP 2.6   En la versión 2.6, AAP utiliza un servicio central de autenticación (Platform Gateway). Este gateway consolida los métodos de login (LDAP, SAML, OIDC, autenticación local, etc.) en un sistema modular y extensible, basado en autenticadores y mapeos.   Cada autenticador define cómo se conecta la plataforma a una fuente externa (como AD), mientras que los mapeos controlan cómo los usuarios autenticados se asocian a organizaciones, equipos o roles dentro de AAP.                  Concepto       Descripción                       Authenticator Plugin       Tipo de conexión (LDAP, SAML, OIDC, etc.).                 Authenticator       Instancia del plugin con su configuración específica (por ejemplo, la URL del servidor LDAP al que necesita conectarse).                 Authenticator Map       Reglas que definen permisos o acceso según grupos o atributos de usuario.              Esta arquitectura “pluggable” permite tener múltiples autenticadores activos, incluso del mismo tipo (por ejemplo, varios LDAP apuntando a distintos dominios o unidades organizativas).    Flujo de autenticación      Requisitos previos   Antes de empezar, tenemos que asegurarnos de tener todo lo necessario:      Ansible Automation Platform 2.6 instalado y operativo.   Una instancia en ejecución de su fuente de autenticación (Active Directory Windows Server 2019 en mi caso) funcionando, con acceso de red desde AAP.   Certificado del servidor LDAPS, en caso de usar conexión segura.   Credenciales de administrador en AAP con acceso a Access Management → Authentication Methods.   Siempre se recomienda usar LDAPS (puerto 636) para cifrar las credenciales y proteger las consultas del dominio.   Guía DEMO   El objetivo de esta guía es integrar Ansible Automation Platform con Active Directory (Windows Server 2019) usando LDAP, de modo que la autenticación de usuarios se gestione desde el directorio corporativo sin necesidad de credenciales locales en AAP.   Primero vamos a crear un nuevo autenticador en Ansible Automation Platform, para ello iniciamos sesión entrando desde el navegador.      En la interfaz de AAP, navegamos hasta Access Management → Authentication Methods → Create authentication.      Una vez aquí podemos ver los métodos de autenticación creados, seleccionamos crear método para configurar otro método de autenticación.   Configuración del método de autenticación   Esta parte es importante vamos a ver cada uno de los campos para entender mejor cómo funciona todo. Es una parte un poco más teórica y larga, así que si ya sabemos cómo van estos parámetros, podemos saltarnos esto i ir directamente al punto “Active Directory Authenticator – Configuración”.           📘 Name  El campo Name sirve para dar un nombre a esta configuración de autenticación.     Por ejemplo, podemos asignarle un nombre descriptivo como:    Active Directory Authenticator         📘 Authentication type  Seleccionamos LDAP en el campo de Authentication type. La sección de Detalles de Autenticación se actualizará automáticamente para mostrar los campos relevantes según el tipo seleccionado.    LDAP          📘 LDAP Server URI  En este campo se debe ingresar la URL del servidor LDAP o Active Directory al cual Ansible Automation Platform (AAP) se conectará para autenticar a los usuarios.    La URL define el protocolo, el nombre del servidor (o su dirección IP), y el puerto de conexión. El formato general es:    ldap://&lt;nombre_servidor&gt;:&lt;puerto&gt;    Por ejemplo, en nuestro caso utilizaremos:    ldap://padthai.org:389       ldap:// indica que se utilizará el protocolo LDAP estándar sin cifrado (el método seguro sería ldaps://).   padthai.org es el nombre del dominio o servidor que aloja el servicio LDAP.   389 es el puerto predeterminado para conexiones LDAP sin TLS (con LDAPS sería 636).   AAP también permite especificar múltiples servidores LDAP en este campo, separados por espacios o comas. Esto es útil para proporcionar alta disponibilidad o tolerancia a fallos. Por ejemplo:    ldap://ldap1.padthai.org:389 ldap://ldap2.padthai.org:389    Cuando sea posible, se recomienda utilizar LDAPS (LDAP sobre SSL) o StartTLS para cifrar la comunicación entre AAP y el servidor de directorio.     El formato para conexiones seguras es:    ldaps://padthai.org:636          📘 LDAP Bind DN  En este campo se especifica el Distinguished Name (DN) del usuario que Ansible Automation Platform (AAP) utilizará para autenticarse contra el servidor LDAP o Active Directory.     Este usuario es conocido como la cuenta de enlace o Bind User, y su función es permitir que AAP realice búsquedas dentro del árbol de directorios para validar las credenciales de los usuarios que intentan iniciar sesión.    El DN (Distinguished Name) es una cadena que identifica de forma única a un objeto dentro de la jerarquía del directorio LDAP. Está compuesto por varios componentes jerárquicos, como:     CN (Common Name): el nombre del objeto o usuario.   OU (Organizational Unit): la unidad organizativa donde se encuentra el objeto (si aplica).   DC (Domain Component): los componentes del dominio, que representan la estructura DNS del dominio de Active Directory.   Por ejemplo, si el usuario que AAP utilizará para enlazarse con el servidor LDAP es el Administrador del dominio, su DN podría tener el siguiente formato (en nuestro caso es este mismo, ya que lo hemos hecho lo más simple posible):    CN=Administrator,CN=Users,DC=padthai,DC=org    Esto indica que:     El nombre común (CN) del usuario es Administrator.   Este usuario se encuentra en el contenedor predeterminado Users.   El dominio al que pertenece está formado por los componentes padthai.org.   En entornos más complejos, el usuario de enlace puede estar ubicado en una unidad organizativa diferente, por ejemplo:    CN=ldap-bind,OU=ServiceAccounts,DC=padthai,DC=org    Por motivos de seguridad, es preferible utilizar una cuenta de servicio dedicada con permisos mínimos de lectura en el directorio, en lugar de la cuenta de administrador del dominio.     Como esto es solo una prueba, hemos utilizado el Administrador, aunque en entornos de producción se debe evitar.       📘 LDAP Bind Password  En este campo se debe ingresar la contraseña del usuario de enlace (Bind DN) configurado previamente.   Esta credencial permite que Ansible Automation Platform (AAP) se autentique ante el servidor LDAP y realice las búsquedas necesarias dentro del directorio.    Por ejemplo, si en el campo LDAP Bind DN se especificó el usuario:    CN=Administrator,CN=Users,DC=padthai,DC=org    Entonces en LDAP Bind Password se debe ingresar la contraseña correspondiente a esta cuenta.    Importante:     Esta contraseña se almacena sin cifrado si se utiliza el protocolo LDAP (puerto 389), ya que la comunicación no está protegida.   Por esta razón, se recomienda utilizar LDAPS (puerto 636) o StartTLS para asegurar la conexión y evitar que las credenciales sean transmitidas en texto plano.   En entornos de laboratorio o pruebas, esto puede no ser crítico, pero nunca debe aplicarse en entornos de producción sin cifrado.   Por motivos de seguridad, en la interfaz de AAP el valor de este campo aparece enmascarado (por ejemplo, como *******), aunque internamente se guarda en texto claro si no se usa cifrado.         📘 LDAP Group Type  Este campo define el tipo de grupos que utiliza el servidor LDAP o Active Directory, y determina cómo Ansible Automation Platform (AAP) interpretará y consultará la pertenencia de los usuarios a dichos grupos.    Dependiendo del tipo de servidor LDAP en uso (por ejemplo, Active Directory, OpenLDAP, FreeIPA, etc.), la estructura interna de los grupos puede variar.     Por ello, AAP requiere que se seleccione el tipo de grupo adecuado para poder realizar correctamente la búsqueda de pertenencias y aplicar los permisos o roles asociados.    Algunos de los tipos de grupo más comunes son:     ActiveDirectoryGroupType — para entornos Microsoft Active Directory.   GroupOfNamesType — para servidores LDAP que usan objetos del tipo groupOfNames.   GroupOfUniqueNamesType — similar al anterior, pero basado en el atributo uniqueMember.   PosixGroupType — para entornos Unix/Linux que utilizan el atributo memberUid.   La lista completa de tipos de grupo disponibles y su descripción detallada puede consultarse en la documentación oficial de Django Auth LDAP:     Documentación oficial de tipos de grupos     En la mayoría de los entornos con Active Directory, el valor correcto será ActiveDirectoryGroupType, ya que coincide con el esquema de grupo utilizado por Microsoft.        📘 LDAP User DN Template  Este campo permite definir una plantilla fija para construir el Distinguished Name (DN) de los usuarios que intentan autenticarse, como alternativa a realizar búsquedas en el directorio.    Cuando todos los usuarios dentro del servidor LDAP o Active Directory siguen una estructura de DN consistente, esta opción puede ser más eficiente que usar el método de búsqueda (User Search Base), ya que evita consultas adicionales al directorio.    La sintaxis general de este campo es:    uid=%(user)s,&lt;ruta_del_contenedor&gt;    o, en el caso de Active Directory:    CN=%(user)s,CN=Users,DC=padthai,DC=org    Donde:     %(user)s se reemplaza automáticamente por el nombre de usuario ingresado en el inicio de sesión.   Los demás componentes (CN, OU, DC, etc.) definen la ubicación en el árbol LDAP donde se encuentran los usuarios.   Por ejemplo, si todos los usuarios del dominio padthai.org se ubican en el contenedor Users, la plantilla podría ser:    CN=%(user)s,CN=Users,DC=padthai,DC=org    Esto permitirá que AAP construya directamente el DN completo de cada usuario a partir del nombre ingresado, sin necesidad de buscarlo en el directorio.      Si se define este campo, AAP ignorará la configuración de User Search Base (AUTH_LDAP_USER_SEARCH).   Esta opción solo debe utilizarse cuando la estructura del directorio es uniforme y todos los usuarios siguen el mismo patrón de DN.   En entornos más complejos, donde los usuarios se distribuyen en varias unidades organizativas (OU), es preferible usar la búsqueda de usuarios (User Search Base) para evitar fallos de autenticación.          📘 LDAP Start TLS  Este parámetro determina si se debe habilitar el cifrado TLS (Transport Layer Security) sobre una conexión LDAP estándar que no usa SSL (es decir, conexiones a través del puerto 389).    Cuando esta opción está activada, Ansible Automation Platform (AAP) establece primero una conexión LDAP sin cifrar y, a continuación, inicia una negociación TLS para proteger la comunicación.     Esto permite mantener el mismo puerto de conexión (389) pero garantizando la confidencialidad e integridad de los datos transmitidos, incluidas las credenciales del usuario de enlace (Bind DN) y las respuestas del servidor.    En términos prácticos:     Si la URL del servidor es ldap://padthai.org:389 y esta opción está habilitada, la sesión LDAP se cifrará mediante TLS.   Si la URL es ldaps://padthai.org:636, no es necesario habilitar StartTLS, ya que la conexión ya está protegida mediante SSL nativo.   Recomendaciones:     En entornos de producción, siempre debe habilitarse StartTLS (o usarse LDAPS) para evitar la transmisión de credenciales en texto claro.   Si se trata de un entorno de laboratorio o pruebas, puede dejarse desactivado, aunque esto implica que las comunicaciones no estarán cifradas.   El servidor LDAP debe tener un certificado válido configurado para que la negociación TLS funcione correctamente.         📘 Additional Authenticator Fields  Este campo permite definir parámetros adicionales que pueden ser utilizados por el autenticador, en este caso el conector LDAP.    Los valores que se introduzcan aquí no son validados ni procesados directamente por Ansible Automation Platform (AAP); en su lugar, son transmitidos tal cual al autenticador subyacente.     Esto ofrece flexibilidad para incluir configuraciones o atributos personalizados que no estén contemplados en los campos estándar de la interfaz.    Por ejemplo, podrían definirse parámetros específicos del entorno o del servidor LDAP, tales como:     AUTH_LDAP_CONNECTION_TIMEOUT: 5  AUTH_LDAP_REQUIRE_GROUP: \"CN=admins,CN=Users,DC=padthai,DC=org\"     En este caso:     AUTH_LDAP_CONNECTION_TIMEOUT establece un tiempo máximo de espera (en segundos) para la conexión LDAP.   AUTH_LDAP_REQUIRE_GROUP obliga a que el usuario pertenezca a un grupo determinado para poder autenticarse en AAP.   Importante:     AAP no valida ni interpreta estos campos, por lo que cualquier error de formato o valor inválido puede causar fallos en la autenticación.   Se recomienda usar esta opción únicamente cuando sea necesario aplicar configuraciones avanzadas o extender el comportamiento predeterminado del autenticador LDAP.   La lista completa de variables adicionales disponibles se puede consultar en la documentación oficial de Django Auth LDAP:     https://django-auth-ldap.readthedocs.io/en/stable/         📘 LDAP Connection Options  Este campo permite definir opciones adicionales de configuración para la conexión LDAP que establece Ansible Automation Platform (AAP) con el servidor de directorio.    Estas opciones se aplican directamente a la biblioteca python-ldap, que es la capa utilizada por AAP (a través de Django Auth LDAP) para gestionar las conexiones.     Se trata, por tanto, de parámetros de bajo nivel que ajustan el comportamiento de la conexión y pueden ser útiles para entornos con configuraciones específicas de Active Directory o LDAP.    Por defecto, AAP deshabilita las referencias LDAP (OPT_REFERRALS = 0) para evitar bloqueos en ciertas consultas realizadas contra servidores Active Directory.     Esto es especialmente importante porque las referencias pueden hacer que las operaciones de búsqueda queden en espera indefinidamente.    Podemos agregar otras opciones según las necesidades de tu entorno, utilizando el formato de clave-valor, donde los nombres de las opciones deben ser cadenas de texto (por ejemplo, \"OPT_NETWORK_TIMEOUT\", \"OPT_DEBUG_LEVEL\", etc.).     Ejemplo:     {  &nbsp;&nbsp;\"OPT_REFERRALS\": 0,  &nbsp;&nbsp;\"OPT_NETWORK_TIMEOUT\": 5,  &nbsp;&nbsp;\"OPT_DEBUG_LEVEL\": 0  }     En este ejemplo:     OPT_REFERRALS: 0 desactiva las referencias LDAP (valor predeterminado).   OPT_NETWORK_TIMEOUT: 5 establece un tiempo máximo de 5 segundos para las operaciones de red.   OPT_DEBUG_LEVEL: 0 define el nivel de depuración (0 = desactivado).   Se recomienda:     Utilizar este campo únicamente para ajustar comportamientos específicos o resolver problemas de conectividad.   Los nombres y valores válidos de las opciones disponibles se encuentran en la documentación oficial de python-ldap:     https://www.python-ldap.org/doc/html/ldap.html#options   Un valor mal configurado puede causar errores de conexión o comportamiento inesperado, por lo que se recomienda probar los cambios en un entorno de desarrollo antes de aplicarlos en producción.        📘 LDAP Group Type Parameters  Este campo permite especificar parámetros adicionales (en formato clave-valor) que serán enviados al método de inicialización del tipo de grupo definido en el campo LDAP Group Type.    Cada tipo de grupo en LDAP —por ejemplo, ActiveDirectoryGroupType, GroupOfNamesType o PosixGroupType— puede requerir o admitir opciones específicas para adaptar su comportamiento al esquema del servidor de directorio.     Estas opciones se pasan al inicializador del tipo de grupo elegido y permiten controlar cómo se interpretan los atributos de pertenencia a grupos o cómo se resuelven los miembros.    Por ejemplo, para un entorno Active Directory, podrías especificar:     {  &nbsp;&nbsp;\"name_attr\": \"cn\"  }     O para un servidor OpenLDAP que utiliza el atributo memberUid:     {  &nbsp;&nbsp;\"member_attr\": \"memberUid\"  }     Estos parámetros le indican al autenticador cómo identificar los grupos y los miembros dentro del árbol LDAP según el esquema utilizado.     Los nombres y valores de los parámetros dependen del tipo de grupo seleccionado en LDAP Group Type.   Si no se requieren configuraciones especiales, este campo puede dejarse vacío.   La lista completa de parámetros disponibles y ejemplos de uso puede consultarse en la documentación oficial de Django Auth LDAP:     https://django-auth-ldap.readthedocs.io/en/stable/groups.html         📘 LDAP Group Search  Este campo define la búsqueda LDAP utilizada para localizar los grupos dentro del directorio.     En Ansible Automation Platform (AAP), esta configuración es fundamental porque permite mapear a los usuarios con las organizaciones, equipos o roles basándose en su pertenencia a grupos definidos en el servidor LDAP o Active Directory.    A diferencia de la búsqueda de usuarios (User Search Base), la búsqueda de grupos:     Se utiliza exclusivamente para identificar grupos y sus miembros.   No admite el uso de LDAPSearchUnion, por lo que solo puede configurarse una única búsqueda LDAP.   El formato general de la búsqueda es similar al utilizado para usuarios y se compone de tres partes principales:    Base DN, Scope, Filter    Por ejemplo:     {  &nbsp;&nbsp;\"base_dn\": \"OU=Groups,DC=padthai,DC=org\",  &nbsp;&nbsp;\"scope\": \"SUBTREE\",  &nbsp;&nbsp;\"filter\": \"(objectClass=group)\"  }     En este ejemplo:     base_dn define el punto de inicio en el árbol LDAP desde donde se buscarán los grupos.   scope puede ser:            BASE — solo el DN exacto especificado.       ONELEVEL — solo los objetos directamente bajo el DN base.       SUBTREE — todos los objetos dentro del DN base (recomendado).           filter especifica el criterio LDAP que determina qué objetos se consideran grupos (por ejemplo, objectClass=group en Active Directory o objectClass=groupOfNames en OpenLDAP).      Debemos asegurarnos de que el filtro y el ámbito de búsqueda coincidan con la estructura real de grupos en tu directorio.   En entornos Active Directory, el contenedor predeterminado suele ser CN=Users,DC=padthai,DC=org, pero en configuraciones más organizadas puede usarse una OU específica como OU=Groups.   Este campo trabaja en conjunto con LDAP Group Type y LDAP Group Type Parameters para determinar cómo se interpretan y procesan los resultados de la búsqueda de grupos.        📘 LDAP User Attribute Map  Este campo define el mapeo entre los atributos del esquema LDAP y los atributos del modelo de usuario de Ansible Automation Platform (AAP).     En otras palabras, indica cómo deben traducirse los datos obtenidos del servidor LDAP (como nombre, apellido, correo electrónico, etc.) a los campos correspondientes del usuario dentro de AAP.    Por defecto, los valores de este mapeo están configurados para ser compatibles con Microsoft Active Directory, pero pueden requerir ajustes si se utiliza otro tipo de servidor LDAP (por ejemplo, OpenLDAP o FreeIPA), ya que los nombres de los atributos pueden variar.    Un ejemplo típico para Active Directory sería:     {  &nbsp;&nbsp;\"first_name\": \"givenName\",  &nbsp;&nbsp;\"last_name\": \"sn\",  &nbsp;&nbsp;\"email\": \"mail\"  }     Mientras que en un entorno OpenLDAP, los atributos podrían ser diferentes:     {  &nbsp;&nbsp;\"first_name\": \"givenName\",  &nbsp;&nbsp;\"last_name\": \"surname\",  &nbsp;&nbsp;\"email\": \"mail\"  }     AAP usa este mapeo al sincronizar usuarios desde el directorio LDAP, garantizando que los datos básicos del usuario (nombre, apellido, correo) se almacenen correctamente en la base de datos interna del sistema.      Si nuestro servidor LDAP utiliza un esquema personalizado, debemos asegurarnos de conocer los nombres exactos de los atributos antes de modificarlos.   Es posible agregar otros campos compatibles con la API de usuarios de AAP si nuestra organización necesita información adicional (por ejemplo, username o phone_number).   Consultar la documentación de AAP o de Django Auth LDAP para obtener la lista completa de atributos compatibles y ejemplos detallados:     https://django-auth-ldap.readthedocs.io/en/stable/          📘 LDAP User Search  Este campo define la búsqueda LDAP utilizada para localizar y autenticar a los usuarios dentro del directorio.     Cuando un usuario intenta iniciar sesión en Ansible Automation Platform (AAP), el sistema ejecuta esta búsqueda para encontrar la entrada correspondiente en el servidor LDAP y validar sus credenciales.    El resultado de esta búsqueda determina qué usuarios pueden autenticarse en la plataforma. Solo los usuarios que coincidan con los criterios especificados podrán iniciar sesión y deberán estar mapeados a una organización mediante la configuración AUTH_LDAP_ORGANIZATION_MAP    La búsqueda se especifica mediante tres componentes principales:    Base DN, Scope, Filter    Por ejemplo:     {  &nbsp;&nbsp;\"base_dn\": \"OU=Users,DC=padthai,DC=org\",  &nbsp;&nbsp;\"scope\": \"SUBTREE\",  &nbsp;&nbsp;\"filter\": \"(sAMAccountName=%(user)s)\"  }     En este ejemplo:       base_dn: indica el punto de partida dentro del árbol LDAP desde donde se buscarán los usuarios (por ejemplo, OU=Users,DC=padthai,DC=org).   scope: define el alcance de la búsqueda:            BASE: busca solo en el DN exacto especificado.       ONELEVEL: busca solo en el nivel inmediatamente inferior al DN base.       SUBTREE: busca en todo el subárbol (recomendado).           filter: especifica el criterio LDAP utilizado para identificar al usuario.      En Active Directory, el atributo más común es sAMAccountName, mientras que en OpenLDAP suele usarse uid.          Si el entorno requiere soportar múltiples búsquedas de usuarios (por ejemplo, cuando los usuarios están distribuidos en diferentes unidades organizativas), se puede utilizar la opción `LDAPSearchUnion`, que permite combinar varias consultas de búsqueda en una sola configuración.     Lo mejor es utilizar filtros específicos para evitar coincidencias no deseadas y mejorar el rendimiento de las búsquedas.   En entornos Active Directory, (sAMAccountName=%(user)s) es el filtro más habitual.   En OpenLDAP, el equivalente común sería (uid=%(user)s).   Debemos assegurarnos de que la búsqueda sea coherente con la estructura real del árbol de usuarios en nuestra organización.   La documentación completa sobre LDAPSearch y LDAPSearchUnion está disponible en:     https://django-auth-ldap.readthedocs.io/en/stable/searches.html        📘 Opciones Generales del Autenticador LDAP  Esta configuración controla cómo se comporta el autenticador LDAP dentro de Ansible Automation Platform (AAP), incluyendo si está activo, si puede crear objetos automáticamente y cómo manejar la pertenencia de usuarios a grupos o organizaciones.    Enabled    Activa o desactiva el autenticador. Si está activado, los usuarios del directorio LDAP o Active Directory podrán autenticarse.     - Activada: el autenticador LDAP valida usuarios.     - Desactivada: AAP ignora este método, aunque la configuración se mantenga.      Mantener desactivada durante pruebas y activarla solo cuando la conexión y autenticación estén verificadas.     Create Objects    Permite que AAP cree automáticamente usuarios, equipos u organizaciones basándose en la información obtenida de LDAP.     - Si un usuario se autentica por primera vez y no existe en AAP, se creará automáticamente.     - Lo mismo aplica para organizaciones o equipos que falten según la configuración.      Habilitar solo si se confía en la integridad del directorio. En entornos grandes puede generar muchos objetos rápidamente.     Remove Users    Controla si al autenticarse un usuario LDAP se eliminan sus pertenencias previas a grupos o equipos asignados desde otras fuentes.     - Activada: el usuario queda solo en los grupos definidos en LDAP.     - Desactivada: conserva las asociaciones anteriores.      Mantener activada si LDAP es la fuente principal de autoridad. Si se usan múltiples autenticadores, puede dejarse desactivada para no perder asociaciones externas.      Finalmente, hacemos clic en Create Authentication Method para guardar la configuración y crear el método de autenticación. Con esta acción, se aplicarán todos los parámetros que hemos definido previamente, completando así el proceso de integración.       Después de toda esta parte teórica, a continuación se muestra una tabla con los valores utilizados para la integración de mi Active Directory con Ansible Automation Platform en un entorno de laboratorio.   Active Directory Authenticator – Configuración   Esta es la configuración que hemos utilizado para esta guia.                  Name       Active Directory Autenticator                       Type       LDAP                 Authentication Enabled       Yes                 LDAP Bind DN       CN=Administrator,CN=Users,DC=padthai,DC=org                 LDAP Bind Password       $encrypted$                 LDAP Group Type       ActiveDirectoryGroupType                 LDAP Start TLS       Off                 LDAP Group Type Parameters       name_attr: cn                 LDAP Server URI       - ldap://padthai.org:389                 LDAP User Attribute Map       email: mail username: sAMAccountName last_name: sn first_name: givenName                 LDAP User Search       - CN=Users,DC=padthai,DC=org - SCOPE_SUBTREE - (sAMAccountName=%(user)s)           Una vez completada la creación, debemos asegurarnos de que el método de autenticación esté habilitado. Además, es posible ordenar los métodos según su prioridad para definir cuál se aplicará primero.      En mi Active Directory tengo un contenedor denominado Users, dentro del cual se encuentra el usuario xavi. Para verificar que Ansible Automation Platform se ha integrado correctamente con el Active Directory, realizaremos una prueba iniciando sesión con este usuario. En la siguiente imagen se muestra la estructura del árbol de mi Active Directory (correspondiente a Windows Server 2019 AD), en el aparece mi usuario.      Regresamos a la pantalla de inicio de sesión de Ansible Automation Platform i introducimos nuestras credenciales para verificar que el acceso funciona.      Si todo funciona correctamente, deberíamos poder iniciar sesión. Es probable que el usuario no disponga de permisos de administrador, por lo que es importante gestionar adecuadamente los niveles de acceso y asignar los privilegios necesarios según el rol de cada usuario.      Con esto finaliza esta guía sobre la integración de Active Directory con Ansible Automation Platform (AAP) a través de LDAP. Cabe destacar que esta configuración está pensada para un entorno de pruebas o desarrollo, ya que se ha utilizado LDAP en lugar de LDAPS, que sería el método recomendado para entornos de producción por motivos de seguridad.  ","categories": ["RedHat","ActiveDirectory"],
        "tags": ["AAP","LDAP","LDAPS","ActiveDirectory","Autenticación"],
        "url": "/redhat/activedirectory/Red-Hat-Ansible-Automation-Platform-2.6-Gu%C3%ADa-de-Integraci%C3%B3n-con-Active-Directory-(LDAP-LDAPS)/",
        "teaser": null
      },{
        "title": "Red Hat Enterprise Linux: Guía de Configuración de un Servidor BIND DNS en RHEL 9.6",
        "excerpt":"Introducción   El DNS (Domain Name System) es el sistema que traduce nombres de dominio legibles por humanos, como www.example.com, en direcciones IP que los ordenadores utilizan para comunicarse.   En un entorno corporativo o incluso doméstico, tener un servidor DNS propio puede mejorar el rendimiento, la seguridad y el control de las consultas de tu red.   En este artículo, veremos como instalar y configurar un servidor DNS con BIND en Red Hat Enterprise Linux (RHEL) 9.6, de forma sencilla y explicando cada paso, los conceptos clave y cómo verificar que todo funcione correctamente.     BIND   BIND (Berkeley Internet Name Domain) es un servidor DNS muy completo y compatible con los estándares de la IETF. Sus usos más comunes incluyen:      Servidor caching para mejorar la velocidad de resolución de nombres.   Servidor autoritativo para zonas que administras.   Servidor secundario para replicar zonas y garantizar alta disponibilidad.   BIND puede ejecutarse en modo normal o en un entorno chroot para mayor seguridad. Además, en RHEL, SELinux protege al servicio por defecto, evitando vulnerabilidades conocidas.     Configuración de Zonas DNS   Una zona DNS es un conjunto de registros que define cómo un dominio se resuelve en direcciones IP, qué servidores pueden responder y qué información adicional existe sobre servicios y políticas del dominio.   En entornos reales, una zona no suele estar en un único servidor; para fiabilidad y redundancia se utilizan servidores primarios y secundarios.     Tipos de zonas   Zonas directas      También llamadas forward zones.   Asocian nombres de dominio a direcciones IP.   Se usan los registros A (IPv4) y AAAA (IPv6).   Ejemplo: resolución directa de www.xebec.dlab a IPv4:   www IN A 192.168.6.29  Zonas inversas      También llamadas reverse zones.   Hacen lo contrario: asocian IP a nombre de dominio.   Se usan los registros PTR.   Ejemplo: resolución inversa de 192.168.6.29 a dns.xebec.dlab:   29.6.168.192.in-addr.arpa. IN PTR dns.xebec.dlab.   Nota: Siempre que tengas una zona directa, se recomienda crear la zona inversa correspondiente para que los servicios de correo, autenticación y seguridad funcionen correctamente.     Registros DNS principales                  Registro       Función principal       Ejemplo                       SOA       Autoridad y control de la zona       @ IN SOA dns.xebec.dlab. admin.xebec.dlab. ( 2026010701 3600 900 604800 86400 )                 NS       Servidores DNS autoritativos       @ IN NS dns1.xebec.dlab.                 A       Nombre → IPv4       www IN A 192.168.6.29                 AAAA       Nombre → IPv6       www IN AAAA 2001:db8::1                 CNAME       Alias DNS       ftp IN CNAME www.xebec.dlab.                 MX       Servidores de correo       @ IN MX 10 mail.xebec.dlab.                 TXT       Texto, políticas y verificación       @ IN TXT \"v=spf1 ip4:192.168.6.29 -all\"                 PTR       IP → Nombre (resolución inversa)       29.6.168.192.in-addr.arpa. IN PTR dns.xebec.dlab.                 SRV       Servicios y puertos       _ldap._tcp IN SRV 0 5 389 ldap.xebec.dlab.           Notas importantes:      Cada zona debe tener un único registro SOA; sin él, la zona no carga.   Los registros NS definen qué servidores pueden responder consultas por la zona.     Parámetros de control del SOA                  Valor       Nombre       Para qué sirve                       2026010701       Serial       Versión de la zona                 3600       Refresh       Cada cuánto el slave consulta cambios en el master                 900       Retry       Tiempo de espera si falla la conexión al master                 604800       Expire       Cuándo la zona deja de ser válida si no se actualiza                 86400       Minimum TTL       Tiempo de caché de las respuestas           Es fundamental incrementar el serial cada vez que se modifica la zona para que los servidores secundarios se sincronicen.     Servidores Master y Slave   Servidor primario (Master)   Es el dueño de la zona, donde se mantienen los registros originales.   Se edita directamente el archivo de zona:   zone \"xebec.dlab\" {     type master;     file \"/var/named/xebec.dlab.zone\"; };   Aquí se definen SOA, NS, A, AAAA, MX, TXT… Incrementar el serial del SOA garantiza que los slaves se sincronicen correctamente.   Servidor secundario (Slave)   No tiene el archivo editable, copia la zona automáticamente desde el master:   Guarda la copia local en /var/named/slaves/xebec.dlab.zone. Responde consultas DNS igual que el master.   Ambos servidores (master y slave) deben aparecer como NS en la zona:   @ IN NS dns1.xebec.dlab.  ; master @ IN NS dns2.xebec.dlab.  ; slave     Flujo de actualización de la zona      Se hace un cambio en el master (ej. agregar un registro A).   Se incrementa el serial del SOA.   El slave detecta el cambio consultando el serial (cada Refresh segundos).   El slave descarga la zona y la guarda localmente.   Ambos servidores pueden responder consultas de forma autoritativa.     Prerrequisitos   Antes de instalar BIND, asegúrate de:      Tener una IP estática en el servidor.   Contar con privilegios de root o un usuario con sudo.   Sin conflictos con otros servicios DNS en el mismo host.   Detalles del sistema utilizado en nuestro caso:                  Categoría       Detalle                       Sistema Operativo       Red Hat Enterprise Linux 9.6 (Plow)                 ID del Sistema       rhel                 Versión       9.6                 Kernel       5.14.0-570.62.1.el9_6.x86_64                 Arquitectura       x86_64                 Interfaz Loopback       lo                 IP Loopback IPv4       127.0.0.1/8                 IP Loopback IPv6       ::1/128                 Interfaz de Red Real       ens192 (altname enp11s0)                 IP IPv4       192.168.6.29/24                 IP IPv6       fe80::20c:29ff:feb4:56e0/64 (link-local)                 Puerta de enlace       192.168.6.1                 Red       192.168.6.0/24                 Estado de interfaces       ambas UP             Demo   Instalación de BIND   Primero instalamos los paquetes necesarios bind y bind-utils   dnf install bind bind-utils     Configuración Básica de BIND   El archivo principal de configuración es /etc/named.conf. Antes de modificarlo, es recomendable hacer una copia de seguridad.   sudo cp /etc/named.conf /etc/named.conf.bak   Ahora entramos en el archivo /etc/named.conf.   El archivo /etc/named.conf tiene un bloque llamado options { … }. Aquí se definen configuraciones globales para tu servidor DNS, como:           En qué interfaces de red escuchará (IPv4 e IPv6).            Qué IP pueden hacer consultas.            Desde qué IP se permite hacer consultas recursivas.       listen-on y listen-on-v6, estas líneas configuran las direcciones IP y puertos en los que el proceso named estará escuchando conexiones entrantes para consultas DNS, separadas por protocolo (IPv4/IPv6)   listen-on port 53 { 127.0.0.1; 192.168.6.0/24; }; listen-on-v6 { ::1; };   El port 53 es el puerto estándar para DNS, listen-on lista de direcciones IPv4 donde escuchará y listen-on-v6 lo mismo pero para IPv6.   allow-query define quién puede consultar tu servidor DNS   allow-query { 127.0.0.1; 192.168.6.0/24; };  En nuestro caso localhost el propio servidor y 192.168.6.0/24 toda la subred IPv4 de 192.168.6.0 a 192.168.6.255.   Esto evita que cualquier IP externa haga consultas a nuestro servidor (lo cual es más seguro).   La línea allow-recursion define quién puede hacer consultas recursivas, es decir, cuando nuestro servidor tiene que buscar la respuesta en otros servidores DNS de internet.   allow-recursion { 127.0.0.1; 192.168.6.0/24; };   Si un cliente no está en esta lista, no podrá hacer consultas recursivas, esto previene que tu servidor sea usado en ataques de amplificación DNS.   Finalmente, nuestro archivo de configuración quedaría de la siguiente manera   Antes de iniciar BIND, verificamos la sintaxis, si el comando no muestra ningún resultado, la sintaxis es correcta.   named-checkconf   Si no hay salida, la sintaxis es correcta.   Permitimos el tráfico DNS en el firewall y arrancamos el servicio     Configuración de Zonas   Zona directa (Forward Zone)   Añadimos la definición de zona en el archivo /etc/named.conf   zone \"xebec.dlab\" {     type master;     file \"/var/named/xebec.dlab.zone\";     allow-query { any; };     allow-transfer { none; }; };  Este servidor actúa como el principal (type master) para la xebec.dlab zone   Guardamos el archivo y volvemos a validar la sintaxis   Creamos el archivo /var/named/xebec.dlab.zone con el siguiente contenido   Establezemos los permisos adecuados para que solo el grupo named lo pueda leer   chown root:named /var/named/xebec.dlab.zone chmod 640 /var/named/xebec.dlab.zone  Verificamos la sintaxis de la zona   named-checkzone xebec.dlab /var/named/xebec.dlab.zone   systemctl reload named  Finalmente verificamos que funciona correctamente   Zona inversa (Reverse Zone)   Primero agregamos una nueva definición de zona al /etc/named.conf   zone \"6.168.192.in-addr.arpa\" {     type master;     file \"/var/named/6.168.192.in-addr.arpa.zone\";     allow-query { any; };     allow-transfer { none; };    };  Verificamos sintaxis   Creamos el archivo /var/named/6.168.192.in-addr.arpa.zone   Asignamos los permisos adecuados igual que hemos hecho el la Zona directa (Forward zone)   chown root:named /var/named/6.168.192.in-addr.arpa.zone chmod 640 /var/named/6.168.192.in-addr.arpa.zone  Verificamos la sintaxis del archivo   named-checkzone 6.168.192.in-addr.arpa /var/named/6.168.192.in-addr.arpa.zone  Y recargamos el BIND    systemctl reload named  Para acabar verificamos que funciona  ","categories": ["RedHat","DNS"],
        "tags": ["RHEL","BIND","DNS"],
        "url": "/redhat/dns/RHEL-Configuracion-BIND-DNS/",
        "teaser": null
      },,{
    "title": "Sobre mí",
    "excerpt":"¡Bienvenido/a a mi espacio digital! Soy técnico DevOps y trabajo en una consultoría tecnológica, dando soporte a clientes con sus sistemas y participando en proyectos de infraestructura IT. Me gusta aprender sobre diferentes tecnologías y ponerlas en práctica   Este espacio nació para compartir lo que voy aprendiendo y haciendo, me sirve para no perder detalles de mis proyectos y, de paso, espero que también pueda ser útil para quien esté pasando por algo parecido.   Tecnologías                                    ","url": "http://localhost:4000/about/"
  },{
    "title": "Blog",
    "excerpt":" ","url": "http://localhost:4000/blog/"
  },{
    "title": "Xavi Vico Martí",
    "excerpt":"                                        Red Hat Enterprise Linux: Guía de Configuración de un Servidor BIND DNS en RHEL 9.6          Aprende a instalar, configurar y administrar un servidor DNS con BIND en Red Hat Enterprise Linux 9.6, incluyendo zonas directas e inversas, regist...          Leer más                                        Red Hat Ansible Automation Platform 2.6: Guía de Integración con Active Directory (LDAP/LDAPS)        Leer más                            Nuevo       Red Hat Enterprise Linux: Integración de RHEL 10 con Active Directory 2019 usando SSSD y realmd                       Nuevo       Red Hat Ansible Automation Platform 2.5: Guía de Instalación en RHEL 10 (Topología Growth Contenerizada)                       Nuevo       Seguridad Empresarial con Red Hat: Más Allá del Código Abierto                ","url": "http://localhost:4000/"
  }]
