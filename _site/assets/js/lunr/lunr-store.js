var store = [{
        "title": "Seguridad Empresarial con Red Hat: Más Allá del Código Abierto",
        "excerpt":"El Paradigma de la Seguridad en el Open Source   El software de código abierto se ha convertido en una pieza clave para impulsar la innovación tecnológica. Su esencia está en la colaboración y la transparencia, lo que ha permitido avances extraordinarios, pero aquí es donde aparece lo que podríamos llamar el dilema del código abierto. Aunque este modelo colaborativo es su mayor fortaleza, también plantea desafíos cuando se trata de adoptarlo a nivel empresarial. No es el código en sí el problema, sino cómo las organizaciones entienden y, sobre todo, cómo gestionan su seguridad y los riesgos asociados.   El panorama de las vulnerabilidades ha cambiado radicalmente en las últimas décadas. Cuando nació el programa Common Vulnerabilities and Exposures (CVE) hace 25 años, se registraron 894 vulnerabilidades de seguridad en su primer año, estamos hablando de 1999. En 2024, esa cifra superó las 40,000. Este crecimiento exponencial ha dejado obsoleta la vieja estrategia de ‘parchearlo todo’, ya no es viable ni inteligente tratar todas las vulnerabilidades por igual. No todos los fallos representan el mismo nivel de riesgo, y centrarse en corregirlos todos sin priorizar ignora un punto clave, si realmente están siendo explotados o no. De hecho, los datos muestran que históricamente menos del 0.5% de las vulnerabilidades llegan a ser explotadas activamente.      Aquí es donde la transparencia del código abierto puede jugar en contra, al ser públicos por naturaleza, los proyectos open source tienden a reportar y documentar una gran cantidad de fallos, incluso los de impacto bajo o moderado, en cambio, muchos proveedores de software propietario no revelan este tipo de vulnerabilidades menores, lo que crea una ilusión de mayor seguridad y un panorama de riesgo mucho más opaco.   Esto da lugar a un doble estándar, las políticas que exigen “Zero Known Vulnerabilities” terminan castigando al código abierto por ser más transparente, en lugar de enfocarse en lo que realmente importa, el riesgo real. Red Hat Product Security Risk Report 2024 lo deja claro. Aunque en 2024 aumentó notablemente el número de CVEs asignados a productos de Red Hat en parte porque el kernel de Linux empezó a funcionar como autoridad oficial para registrar fallos (CNA), el riesgo real detrás de esos números no cambió mucho, la mayoría de esas nuevas vulnerabilidades eran de bajo o moderado impacto, lo que refuerza una idea clave, necesitamos evaluar el riesgo con criterio, no simplemente contar vulnerabilidades.   El caso de XZ Backdoor, también abordado en el informe, fue una verdadera llamada de atención a nivel global sobre lo sofisticados que se han vuelto los ataques a la cadena de suministro de software (SSCA). Un atacante logró infiltrarse durante casi dos años, ganándose la confianza de la comunidad, hasta que finalmente introdujo código malicioso con el potencial de comprometer una enorme cantidad de sistemas.   Este incidente puso en evidencia lo crítica que es la seguridad en la cadena de suministro. Pero también dejó algo muy claro, el modelo de código abierto tiene una fortaleza única, gracias a la transparencia del código, la comunidad detectó y reaccionó rápidamente de forma colaborativa, esa respuesta ágil y abierta fue clave para contener la amenaza a tiempo.   Red Hat no se limita a usar software de código abierto, participa activamente en su evolución, lo mantiene y lo fortalece, es un actor clave dentro del ecosistema, con un conocimiento profundo de las normativas globales y una visión anticipada de las amenazas emergentes, Red Hat incorpora la seguridad desde el inicio y a lo largo de todo su ciclo de desarrollo de software (RHSDLC).   Además, su rol como participante raíz del programa CVE y CNA lo coloca en una posición única, no solo identifica y evalúa vulnerabilidades, sino que ofrece a sus clientes soluciones concretas y respaldadas por un nivel de experiencia difícil de igualar.   Las organizaciones necesitan más que solo software de código abierto, necesitan una plataforma open source reforzada, gestionada y segura por diseño, aquí es donde los productos de Red Hat marcan la diferencia.   Red Hat Enterprise Linux (RHEL): La Base Reforzada   Toda estrategia de seguridad empresarial robusta debe construirse sobre una base sólida, en el ecosistema de Red Hat, esa base es Red Hat Enterprise Linux (RHEL), no todas las distribuciones de Linux son iguales en lo que a seguridad se refiere. RHEL se distingue por un enfoque proactivo que abarca desde el cumplimiento de normativas globales y el endurecimiento del sistema hasta la preparación para amenazas emergentes, a continuación, exploramos algunas de las capas de defensa fundamentales integradas en RHEL.   SELinux: Control de Acceso Obligatorio por Defecto  La seguridad empresarial no consiste únicamente en cerrar puertos y aplicar parches, es una estrategia continua que debe abarcar el control de acceso, la integridad del software, la detección de intrusiones y la gestión proactiva de vulnerabilidades.   La primera línea de defensa es controlar estrictamente quién puede acceder a qué recursos y qué software puede ejecutarse, y no se puede hablar de seguridad en RHEL sin mencionar a SELinux (Security-Enhanced Linux), una herramienta de seguridad avanzada que viene activada por defecto en sistemas RHEL.   Aunque SELinux puede parecer una fuente de complicaciones especialmente cuando impide que aplicaciones personalizadas funcionen o bloquea el acceso a ciertas rutas o puertos, en realidad está haciendo su trabajo, aplicar un modelo de Control de Acceso Obligatorio (MAC). A diferencia del enfoque tradicional basado en permisos de archivos (DAC), SELinux define políticas estrictas y altamente granulares que controlan el comportamiento de usuarios, servicios y procesos. Utiliza etiquetas y tipos para decidir qué acciones están permitidas en archivos, carpetas y puertos, y cuáles no.   Tomemos el servicio web httpd como ejemplo práctico.   Por defecto:      El proceso httpd se ejecuta con el tipo SELinux httpd_t         El contenido en /var/www/html/ tiene la etiqueta httpd_sys_content_t, lo que permite que el servicio acceda a esos archivos.         Los puertos habituales como 80, 443, 8008 y 8443 están etiquetados como http_port_t, lo que autoriza a httpd a utilizarlos.      Supongamos que decidimos desplegar un sitio personalizado en /var/www/my_site y queremos servirlo desde el puerto 4449, en ese momento, SELinux va a bloquear la operación. ¿Por qué? Porque ni el directorio ni el puerto tienen las etiquetas adecuadas, para que httpd pueda operar correctamente, debemos etiquetar el nuevo directorio con httpd_sys_content_t y asociar el puerto 4449 con el tipo http_port_t.   Este tipo de intervenciones son comunes cuando se trabaja con aplicaciones personalizadas, y lejos de ser una molestia, representan una oportunidad para reforzar la seguridad, asegurándonos de que nada fuera de lo previsto pueda ejecutarse sin autorización explícita.   Afortunadamente, RHEL ofrece herramientas para facilitar este proceso. Por ejemplo, existe un rol de sistema específico para SELinux en Ansible, que permite automatizar la verificación y asignación de etiquetas de forma sencilla y repetible, ideal para despliegues a gran escala o entornos CI/CD, estos son algunos ejemplos del rol rhel-system-roles.selinux.         ### AIDE: Monitorización de la Integridad del Sistema   Mientras SELinux proporciona una defensa proactiva al prevenir acciones no autorizadas, una estrategia completa también necesita detectar cambios que ya han ocurrido, aquí es donde la monitorización de la integridad de archivos se vuelve crucial, uno de los métodos más comunes utilizados por atacantes consiste en modificar archivos o procesos ya existentes dentro del sistema, inyectando código malicioso o alterando configuraciones críticas. Este tipo de cambios, muchas veces sutiles, pueden abrir la puerta a vulnerabilidades graves o ser el inicio de un ataque más amplio.   Para enfrentar este riesgo, RHEL incluye AIDE (Advanced Intrusion Detection Environment), una herramienta que actúa como un sistema de monitoreo de integridad. Su función principal es detectar cualquier cambio no autorizado en los archivos del sistema, lo hace manteniendo una base de datos con el estado esperado de cada archivo y directorio, y comparándola con el estado actual del sistema, así, si se añade, borra, modifica o mueve un archivo, AIDE lo reportará.   Se necesita crear una base de datos inicial que represente el estado actual del sistema      Esto generará un archivo con el nombre /var/lib/aide/aide.db.new.gz, esta base de datos contiene hashes y metadatos de los archivos escaneados. En una instalación típica puede incluir más de 50.000 entradas.   Para empezar a usar esta base como referencia para futuros chequeos, simplemente se renombra a aide.db.gz, lo podemos hacer escribiendo en la terminal sudo mv /var/lib/aide/aide.db.new.gz /var/lib/aide/aide.db.gz   Con AIDE ya configurado, puedes comenzar a detectar cambios en el sistema en cualquier momento ejecutando aide –-check, puedes configurar en /etc/aide.conf los cambios que quieres que detecte.   En caso de encontrar diferencias entre la base de datos y el sistema actual, AIDE informará detalladamente. En este ejemplo creo un archivo dentro del directorio /root llamado test-aide-demo, al analizar la base de datos automáticamente detecta los cambios e informa.      Esto puede indicar que un archivo fue modificado, agregado o incluso solo accedido.   Esto garantiza que cualquier cambio inesperado en el sistema pueda ser detectado rápidamente, permitiendo tomar acciones antes de que se conviertan en una brecha de seguridad.   Red Hat Insights: Seguridad Predictiva y a Escala   Mientras que herramientas como SELinux y AIDE aseguran la integridad de un sistema individual, el verdadero desafío empresarial es aplicar esta disciplina a escala. ¿Cómo garantizamos que cientos o miles de sistemas no solo estén protegidos, sino que cumplan con normativas y respondan a las amenazas de forma unificada? Aquí es donde la estrategia de Red Hat escala con Red Hat Insights.   Imaginate un analista de sistemas experto revisando incansablemente cada uno de sus sistemas RHEL, 24/7, este analista no solo detecta problemas, sino que predice fallos y entrega la solución exacta, a menudo como un script de automatización listo para usar, eso es, en esencia, Red Hat Insights   Es un servicio SaaS (Software como Servicio) que se conecta de forma segura a tu entorno RHEL, ya sea on-premise, en la nube pública o en un entorno híbrido, recopila datos anónimos de configuración y telemetría, los compara con una knowledge base masiva curada por los ingenieros de Red Hat y te devuelve recomendaciones personalizadas y priorizadas. Veamos cómo transforma los desafíos diarios en tareas manejables.   No se limita a detectar problemas de seguridad los entiende y te ayuda a resolverlos, su servicio de Vulnerability va mucho más allá de mostrar una lista de CVEs. Por cada vulnerabilidad encontrada, te ofrece contexto claro y útil, qué sistemas están afectados, qué tan grave es (según el estándar CVSS), y lo más importante, si ya existe un exploit conocido que podría ser usado por atacantes, además, guía paso a paso hacia la solución, indicando exactamente qué actualización aplicar o qué recurso técnico consultar para resolver la vulnerabilidad.   Y aquí es donde pasa de ser una herramienta de análisis a una de acción si una vulnerabilidad crítica afecta a decenas o cientos de servidores, corregirla uno por uno sería lento, complicado y con riesgo de error. Insights automatiza ese proceso generando, con un solo clic, un Playbook personalizado. Este no es un guion genérico, sino un conjunto de instrucciones precisas para aplicar solo en los sistemas que tú elijas, con las tareas exactas para solucionar la vulnerabilidad.      Es importante destacar que Red Hat Insights es una plataforma multifacética que va mucho más allá de la seguridad, sus servicios también abarcan la gestión proactiva del cumplimiento (Compliance), la optimización del rendimiento y la estabilidad (Advisor) y el análisis de la configuración, sin embargo, en esta ocasión, únicamente mencionamos Vulnerability, ya que aborda de manera directa el dilema del volumen de CVEs y la necesidad de una gestión basada en el riesgo real.   Red Hat Ansible Automation Platform: Automatización como Defensa   Tener un plan de remediación automatizado es solo la mitad de la batalla. ¿Cómo se ejecuta ese plan de forma segura, controlada y auditable en toda la empresa? Aquí es donde entra Red Hat Ansible Automation Platform (AAP)   Ansible proporciona un lenguaje común y un motor de automatización unificado que permite a los equipos de seguridad orquestar acciones a través de múltiples productos y proveedores. Transforma tareas complejas y manuales en playbooks simples, legibles por humanos y reutilizables, esto no solo acelera drásticamente la respuesta a incidentes, sino que también fomenta una cultura de colaboración, donde tanto los analistas de seguridad como los operadores de TI pueden entender, verificar y ejecutar las mismas automatizaciones.   Orquestación del Firewall: De la Detección a la Contención   El firewall de una organización es su portero digital, el guardián que decide qué tráfico entra y sale de la red, gestionar sus reglas es una de las tareas más críticas y, a menudo, más tediosas, en un entorno empresarial típico, esto implica interactuar con soluciones de proveedores como Check Point, Palo Alto Networks, Fortinet, y otros, cada uno tiene su propia API y su propia lógica. A través de roles y colecciones de contenido certificado, AAP facilita la interacción con distintos proveedores sin necesidad de adaptarse a cada interfaz o API específica.      Consideremos un escenario de respuesta a incidentes clásico, un sistema de monitorización detecta un comportamiento sospechoso proveniente de una dirección IP externa. El análisis confirma que se trata de un intento de ataque. La necesidad es inmediata, bloquear esa IP en el firewall perimetral para detener la amenaza en seco.   En un flujo de trabajo tradicional, este sería un proceso manual. Con Ansible, se convierte en una acción instantánea y automatizada. Utilizando el rol ansible_security.acl_manager, un analista puede ejecutar un playbook preaprobado y extraordinariamente simple. Este playbook no requiere conocimientos profundos de la sintaxis específica del firewall simplemente define la intención, se especifican variables claras y concisas como la IP de origen a bloquear, la IP de destino que se está protegiendo, y el tipo de sistema      Al ejecutar este playbook, Ansible se conecta a la API del servidor de gestión de Check Point y traduce esta simple intención en las acciones necesarias para crear y aplicar una nueva regla de seguridad, en segundos, la IP del atacante es bloqueada, la amenaza se contiene, y todo el proceso queda registrado y es auditable.   La misma lógica se aplica a la inversa, una vez que el incidente ha sido investigado y resuelto, la misma acl_manager puede ser utilizada con una tarea de unblock_ip para eliminar la regla, asegurando que los bloqueos temporales no se conviertan en problemas operativos permanentes. Esta capacidad de gestionar el ciclo de vida completo de una regla de firewall de forma programática, rápida y consistente es un cambio fundamental para cualquier equipo de seguridad   Gestión de IDPS: Despliegue de Reglas a Escala   Si el firewall es ‘el portero’, el Sistema de Detección y Prevención de Intrusiones (IDPS) es el perro guardián que patrulla constantemente la red, buscando patrones de comportamiento malicioso. Herramientas como Snort son increíblemente potentes, pero su eficacia depende enteramente de la calidad y actualidad de sus reglas, cuando surge una nueva amenaza o se descubre una nueva técnica de ataque, es crucial desplegar una nueva firma de detección en todos los sensores de IDPS de la organización de manera rápida y uniforme.   Aquí, de nuevo, el proceso manual es un cuello de botella, iniciar sesión en cada servidor de Snort para editar manualmente los archivos de reglas es lento, propenso a errores de copia y pega, y difícil de escalar, a través de roles como ansible_security.ids_rule, los equipos pueden gestionar las firmas de Snort como si fueran código.   Imaginemos que el equipo de seguridad descubre un nuevo tipo de ataque que intenta acceder al archivo /etc/passwd a través de peticiones web, se necesita una regla para detectar este patrón de inmediato, en lugar de enviar un correo electrónico con instrucciones, se crea un playbook.   Este playbook es un ejemplo de claridad y potencia, primero, se asegura de que la automatización se ejecute con los privilegios necesarios en el servidor Snort (become: true). Luego, especifica el proveedor (ids_provider: snort). La parte más importante es la propia regla, definida en la variable ids_rule en la sintaxis nativa de Snort, pero gestionada y desplegada por Ansible. El playbook también indica exactamente dónde debe escribirse la regla (ids_rules_file) y que su estado debe ser presente, es decir, que se cree si no existe.      Con la ejecución de ansible-navigator, este playbook se conecta a todos los servidores Snort definidos en el inventario y añade la nueva regla de forma atómica y consistente. La verificación es tan simple como conectarse a uno de los servidores y comprobar que la nueva línea ha sido añadida al final del archivo de reglas.   Los ejemplos de gestión de firewalls y IDPS son potentes por sí solos, pero su verdadero valor transformador se revela cuando se combinan en flujos de trabajo de seguridad orquestados. Ansible Automation Platform no solo ejecuta tareas aisladas, permite construir una respuesta a incidentes coherente y de múltiples pasos que se ejecuta a la velocidad de la máquina, no a la velocidad humana.   Este nivel de automatización reduce el tiempo medio de respuesta (MTTR) de horas a meros segundos. Libera a los analistas de seguridad de tareas repetitivas y les permite centrarse en actividades de mayor valor, como la caza de amenazas y el análisis estratégico   Red Hat OpenShift: Seguridad en la Cadena de Suministro de Software   Hemos asegurado el sistema operativo y automatizado su gestión, pero las aplicaciones modernas ya no viven ahí, hoy se ejecutan en contenedores y se despliegan en nubes híbridas, por eso, la estrategia de seguridad de Red Hat se extiende naturalmente a esta capa con ‘Red Hat OpenShift’.   En este apartado, nos enfocaremos en un aspecto clave de esa seguridad, la protección de la cadena de suministro de software (software supply chain). No cubriremos toda la seguridad de OpenShift, sino cómo garantizar que, desde la construcción hasta el despliegue, las aplicaciones sean legítimas, confiables y seguras.   Construyendo una Cadena de Suministro Confiable   El incidente XZ backdoor fue una llamada de atención global, la seguridad no puede empezar en el servidor de producción, sino desde el origen mismo del software, para el mundo de los contenedores, esto significa proteger toda la cadena de suministro, desde la construcción de la imagen hasta su despliegue final.   Construir una cadena de suministro segura y confiable requiere cuidar cada etapa del ciclo de vida del software, desde la escritura del código hasta su puesta en producción.   Todo comienza con la elección de una imagen base. Hoy existen miles de imágenes en repositorios públicos, pero no todas ofrecen el mismo nivel de calidad, mantenimiento o seguridad. Por eso, es responsabilidad de cada equipo elegir cuidadosamente.      Muchas organizaciones prefieren partir de una imagen base mínima, confiable y mantenida, como las Red Hat Universal Base Images (UBI), estas contienen solo lo esencial, lo que permite mantener el control total para aplicar parches rápido y reducir la superficie de ataque, agregando solo los frameworks y librerías que la aplicación necesita.   Pero, aunque una aplicación pase todas las pruebas de seguridad y funcione perfectamente, ¿cómo estar seguros de que realmente fue construida con nuestro código legítimo? Un atacante podría haber insertado código malicioso que robe información sin alterar el comportamiento visible.   Antes, documentos físicos se protegían con sellos que garantizaban su integridad. Hoy, esa función la cumplen las firmas criptográficas.   Firmar digitalmente el código fuente es un primer paso fundamental. Cada cambio debe llevar una firma que confirme la identidad del autor y asegure que el código no fue alterado. Las pipelines de CI/CD deben rechazar automáticamente cualquier commit sin firma válida.   Del mismo modo, las imágenes de contenedor deben firmarse en el momento de su creación, para asegurar que provienen de una fuente confiable y no han sido modificadas. Plataformas como OpenShift pueden validar estas firmas antes del despliegue, permitiendo solo la ejecución de imágenes autorizadas.      Escaneo Continuo y SBOM: Visibilidad y Control   Incluso siguiendo estas mejores prácticas, el riesgo de vulnerabilidades persiste, estas pueden venir desde la imagen base o surgir durante la construcción de la aplicación.   Por eso, es crucial escanear las imágenes en distintos puntos, revisar periódicamente las imágenes base y, si se detecta alguna vulnerabilidad, reconstruirlas y actualizarlas, además, escanear cada nueva imagen antes de pasarla a producción, bloqueando cualquier imagen con fallas críticas para devolverla al equipo de desarrollo.   Para tener visibilidad total sobre los componentes que integran una imagen, es fundamental generar un Software Bill of Materials (SBOM), que documenta todas las librerías, frameworks y dependencias, facilitando auditorías y evaluaciones de riesgo. Este inventario debe generarse y almacenarse junto con la imagen en el registro de contenedores.   La Solución Integrada: Red Hat Trusted Software Supply Chain   Para enfrentar todos estos desafíos, Red Hat ofrece la Red Hat Trusted Software Supply Chain, una colección de soluciones integradas que incorporan seguridad en cada etapa del ciclo de vida de las aplicaciones nativas de la nube.      En lugar de que los equipos deban armar y asegurar por su cuenta una cadena de herramientas y componentes dispares, Red Hat entrega una plataforma completa, fácil de usar y cohesiva, que conecta todo de forma segura y confiable.   La plataforma integra un conjunto de herramientas diseñadas para cubrir todo el ciclo de vida del software, desde el desarrollo hasta la producción, asegurando agilidad y confianza en cada etapa. Para la fase de desarrollo, Red Hat Developer Hub actúa como un portal centralizado que simplifica la creación de aplicaciones, permitiendo a los equipos enfocarse en el código en lugar de la complejidad de la infraestructura. Este proceso se construye sobre las Universal Base Images, que ofrecen un cimiento fiable y seguro para minimizar riesgos desde el inicio.   Para asegurar la cadena de suministro, Trusted Artefact Signer aplica una firma digital al software para validar su autenticidad. A su vez, Trusted Profile Analyzer evalúa de forma inteligente las dependencias para identificar solo las vulnerabilidades que suponen un riesgo real. La gestión de estas imágenes se centraliza en Quay, un registro que las almacena de forma segura y las analiza continuamente en busca de amenazas.   Finalmente, OpenShift actúa como el motor de orquestación que automatiza el despliegue y la gestión de las aplicaciones, mientras que Advanced Cluster Security añade una capa de protección en tiempo de ejecución, monitoreando el entorno y garantizando el cumplimiento de las políticas de seguridad.   Con esta oferta, Red Hat acompaña a los equipos para construir, verificar y desplegar software seguro y confiable, desde el primer código hasta la aplicación en producción.   Conclusiones y Reflexiones Finales   El modelo open source, por su naturaleza transparente, tiende a reportar más vulnerabilidades que el software propietario, lo cual no significa que sea menos seguro, sino que permite un análisis más honesto y riguroso del riesgo real. En lugar de dejarnos llevar por el número de CVEs publicados, debemos cambiar el foco hacia la verdadera prioridad, entender qué vulnerabilidades representan un riesgo real y cuáles no. Este enfoque basado en el riesgo y no en la cantidad es indispensable en un mundo donde la estrategia de parches tradicional ya no es suficiente.   Red Hat demuestra que no basta con consumir software libre, sino que se requiere un enfoque proactivo y estructurado para convertirlo en una verdadera plataforma empresarial segura. Herramientas como las que hemos hablado aquí, permiten construir una defensa integral que abarca desde el control de accesos, hasta la seguridad en entornos de contenedores. Todo esto bajo una misma visión coherente, donde la protección se integra desde la creación del software hasta su despliegue.  ","categories": ["Seguridad","Red Hat","Open Source"],
        "tags": ["RHEL","SELinux","Ansible","OpenShift","CVE","Seguridad Empresarial"],
        "url": "/seguridad/red%20hat/open%20source/Seguridad-empresarial-con-red-hat/",
        "teaser": null
      },{
        "title": "Red Hat Ansible Automation Platform 2.5: Guía de Instalación en RHEL 10 (Topología Growth Contenerizada)",
        "excerpt":"Red Hat Ansible Automation Platform 2.5: Tu Guía Práctica de Instalación en RHEL 10 (Topología Growth Contenerizada)   Introducción   Esta guía sirve para ver el proceso de instalación de Red Hat Ansible Automation Platform (AAP) 2.5 en un entorno Red Hat Enterprise Linux (RHEL) 10. El objetivo es instalar AAP utilizando una topología “Growth” contenerizada, lo que significa que todos los componentes se instalarán en una única máquina virtual.   Esta configuración es perfecta para desarrolladores, para realizar pruebas o para pequeñas implementaciones donde estás comenzando a explorar el poder de la automatización con AAP. Además, lo mejor de esta topología es su flexibilidad, se podrá escalar a una arquitectura “Enterprise” más compleja, con alta disponibilidad y recursos distribuidos.   En este artículo, revisaremos los requisitos previos del sistema, la configuración esencial del entorno y los componentes clave de AAP, para tener una base sólida antes de empezar la instalación paso a paso.   Entendiendo Ansible Automation Platform (AAP)   Antes de meternos de lleno en los detalles técnicos, es fundamental entender qué es exactamente Ansible Automation Platform y por qué se ha convertido en una herramienta tan valiosa.   Para situarnos mejor, vamos a entender conceptos:      Ansible: el motor de automatización, la herramienta base que permite definir y ejecutar tareas en servidores y sistemas.   AWX: el proyecto open source que añade una interfaz gráfica y servicios básicos para gestionar Ansible de forma más cómoda.   AAP (Ansible Automation Platform): la versión empresarial respaldada por Red Hat, que parte de AWX y lo expande con seguridad, soporte oficial y funcionalidades avanzadas para producción y grandes organizaciones.   Imagina que tienes que realizar la misma tarea repetidamente en decenas, o incluso cientos, de servidores o sistemas. Suena aburrido y un palo…, Ansible nació para resolver ese problema, permite escribir instrucciones que tus sistemas pueden ejecutar por ti, como, por ejemplo: “instalar un servidor web Apache en todos mis servidores Linux”. Pues bien, AAP eleva esta capacidad a un nivel empresarial.   Piensa en AAP como la versión corporativa y robusta de AWX, el proyecto de código abierto y gratuito de Ansible. Mientras que AWX es fantástico para experimentar y familiarizarte con la interfaz y los conceptos de automatización, AAP añade capas críticas de seguridad, un soporte oficial de Red Hat inestimable, y herramientas avanzadas para gestionar entornos de gran escala con total confianza. No se limita a ejecutar comandos; AAP te ayuda a orquestar procesos complejos, centralizar inventarios y credenciales, y facilitar el trabajo en equipo a través de una interfaz gráfica intuitiva.   Muchas organizaciones empiezan con AWX para probar las aguas, pero cuando la automatización se convierte en un pilar fundamental de sus operaciones, necesitan una plataforma estable, respaldada y con funcionalidades avanzadas. Ahí es precisamente donde brilla AAP, incluyendo componentes como Automation Controller, Execution Environments, Automation Mesh, acceso a contenido validado, parches de seguridad y, crucialmente, el soporte oficial de Red Hat.   Topologías y Métodos de Instalación   Cuando instalas Ansible Automation Platform, la forma en que decides organizar tu infraestructura se conoce como “topología”. Esto define cómo se distribuyen los diferentes componentes de AAP en tus servidores y cómo se interconectan para asegurar un rendimiento óptimo y una operación estable.   Red Hat valida y recomienda ciertas topologías de despliegue para asegurar que la plataforma funcione de manera fiable y con soporte completo:      Topología Enterprise: Diseñada para organizaciones grandes o entornos de producción críticos. Se enfoca en alta disponibilidad, máximo rendimiento y escalabilidad para manejar grandes volúmenes de usuarios y cargas de trabajo sin interrupciones.   Topología Growth: Ideal para organizaciones más pequeñas, entornos de desarrollo o con recursos limitados. Permite un despliegue más simple y económico al principio, con la flexibilidad de crecer y escalar a medida que tus necesidades evolucionan.   Es importante recordar que, si bien puedes instalar AAP en otras configuraciones, Red Hat solo garantiza soporte completo para las topologías que ellos mismos han probado y publicado. Utilizar una topología validada asegura que tu plataforma sea estable y confiable a largo plazo.   Existen tres métodos principales para instalar y desplegar Ansible Automation Platform 2.5, dependiendo de tu infraestructura y tus preferencias de gestión. Para esta guía, nos centraremos en el método “Contenedores” y la topología “Growth”.                  Método       Infraestructura       Descripción       Topologías probadas                       RPM       Máquinas virtuales y servidores físicos       El instalador RPM despliega AAP en Red Hat Enterprise Linux utilizando paquetes RPM. El cliente gestiona el ciclo de vida del producto e infraestructura.       RPM growth topology, RPM enterprise topology                 Contenedores       Máquinas virtuales y servidores físicos       El instalador basado en contenedores utiliza Podman para ejecutar AAP en contenedores sobre RHEL. El cliente gestiona el ciclo de vida del producto e infraestructura.       Container growth topology, Container enterprise topology                 Operator       Red Hat OpenShift       El operador despliega AAP dentro de OpenShift usando Red Hat OpenShift Operators. El cliente gestiona el ciclo de vida del producto e infraestructura.       Operator growth topology, Operator enterprise topology           Componentes   Para armar el “rompecabezas” de Ansible Automation Platform, es crucial conocer las piezas que lo componen. AAP no es solo una herramienta, sino un ecosistema de servicios interconectados que trabajan juntos para potenciar tu automatización.   Los componentes más importantes que debemos conocer, basándome en la documentación oficial de Red Hat:                  Componente       Descripción       ¿Por qué importa?                       Platform Gateway       La puerta de entrada a AAP. Maneja autenticación, permisos y guarda un registro de cambios (activity stream).       Te logueas una sola vez y accedes a todo. Además, tienes trazabilidad de lo que pasa.                 Automation Controller       El cerebro de la plataforma. Define, ejecuta y escala automatizaciones.       Permite orquestar playbooks desde lo simple hasta lo empresarial.                 Automation Hub       El “mercado central” de colecciones certificadas por Red Hat y partners.       Usas contenido probado y soportado, sin reinventar la rueda.                 Private Automation Hub       Tu propio hub privado y desconectado. Sincroniza contenido y guarda colecciones personalizadas.       Ideal para entornos on-premise o integrados con CI/CD.                 High Availability Hub       Una versión redundante y escalable del hub con múltiples nodos.       Alta disponibilidad = menos caídas y más tranquilidad.                 Event-Driven Ansible Controller       Automatización reactiva: escucha eventos y ejecuta acciones con rulebooks.       Aumenta la agilidad y automatiza decisiones en tiempo real.                 Automation Mesh       Una red de nodos distribuida que reparte la carga de trabajo.       Escalabilidad, resiliencia y flexibilidad en entornos grandes o dispersos.                 Execution Environments       Contenedores donde se ejecutan los playbooks. Incluyen motor + módulos.       Portabilidad y consistencia: “si funciona aquí, funciona en todos lados”.                 Ansible Galaxy       Comunidad para compartir roles y colecciones.       Reutilizas contenido y aceleras tus proyectos.                 Content Navigator       Interfaz de texto (TUI) y CLI principal para construir y ejecutar automatizaciones.       Tu navaja suiza en la terminal, base de futuros IDEs.                 PostgreSQL       Base de datos relacional donde se guarda todo: inventarios, credenciales, historial.       La memoria de la plataforma.           Detalles Técnicos   Esta sección se enfoca en los requisitos validados por Red Hat para una instalación “Growth” contenerizada. Aquí muestro el diseño y las especificaciones para desplegar AAP en una única máquina virtual, de forma clara y sencilla.   Virtual machine requirements   Estos son los requisitos mínimos de hardware para tu VM de RHEL 10 en una topología “Growth”:                  Requirement       Minimum requirement                       RAM       16 GB                 CPUs       4                 Local disk       Total available disk space: 60 GB Installation directory: 15 GB (if on a dedicated partition) /var/tmp for online installations: 1 GB /var/tmp for offline or bundled installations: 3 GB Temporary directory (defaults to /tmp) for offline or bundled installations: 10GB                 Disk IOPS       3000           System configuration   Estos son los aspectos clave que tu sistema RHEL 10 debe cumplir. Atención a la suscripción, ya que es un paso que a menudo se pasa por alto y puede causar problemas:                  Tipo       Descripción       Notas                       Suscripción       Suscripción válida de Red Hat Ansible Automation Platform Suscripción válida de Red Hat Enterprise Linux (para poder usar los repositorios BaseOS y AppStream)                         Sistema operativo       Red Hat Enterprise Linux 9.2 o versiones posteriores de Red Hat Enterprise Linux 9. Red Hat Enterprise Linux 10 o versiones posteriores de Red Hat Enterprise Linux 10.       —                 Arquitectura de CPU       x86_64, AArch64, s390x (IBM Z), ppc64le (IBM Power)       —                 ansible-core       RHEL 9: el programa de instalación usa ansible-core 2.14; la operación de Ansible Automation Platform usa ansible-core 2.16. RHEL 10: el programa de instalación y la operación de Ansible Automation Platform usan ansible-core 2.16.       El programa de instalación utiliza el paquete ansible-core del repositorio AppStream de RHEL. Ansible Automation Platform incluye ansible-core 2.16 para su operación, por lo que no es necesario instalarlo manualmente.                 Navegador       Una versión actualmente soportada de Mozilla Firefox o Google Chrome       —                 Base de datos       PostgreSQL 15       Las bases de datos externas (soporte por el cliente) requieren soporte ICU.           Network ports and protocols   A continuación, se listan los puertos de red y protocolos que AAP utiliza para la comunicación entre sus componentes. Es crucial que estos puertos estén abiertos en el firewall para asegurar la correcta operación de la plataforma:                  Port number       Protocol       Service       Source       Destination                       80/443       TCP       HTTP/HTTPS       Event-Driven Ansible       Automation hub                 80/443       TCP       HTTP/HTTPS       Event-Driven Ansible       Automation controller                 80/443       TCP       HTTP/HTTPS       Automation controller       Automation hub                 80/443       TCP       HTTP/HTTPS       Platform gateway       Automation controller                 80/443       TCP       HTTP/HTTPS       Platform gateway       Automation hub                 80/443       TCP       HTTP/HTTPS       Platform gateway       Event-Driven Ansible                 5432       TCP       PostgreSQL       Event-Driven Ansible       External database                 5432       TCP       PostgreSQL       Platform gateway       External database                 5432       TCP       PostgreSQL       Automation hub       External database                 5432       TCP       PostgreSQL       Automation controller       External database                 6379       TCP       Redis       Event-Driven Ansible       Redis container                 6379       TCP       Redis       Platform gateway       Redis container                 8443       TCP       HTTPS       Platform gateway       Platform gateway                 27199       TCP       Receptor       Automation controller       Execution container           PRACTICA - Instalación de Ansible Automation Platform   La instalación de Ansible Automation Platform requiere una serie de pasos preparatorios para asegurar un despliegue sin problemas. Nos centraremos en una instalación “Growth” contenerizada en RHEL 10.   Preparación del Sistema Operativo   Configuración del Usuario y Privilegios Sudo   Para la instalación, el usuario que ejecuta el instalador debe tener permisos para elevar privilegios a root sin necesidad de introducir una contraseña. Esto es fundamental, ya que muchos pasos del proceso requieren modificar servicios, paquetes y configuraciones críticas del sistema.   Para configurar esto, editamos el archivo sudoers (lo recomendado es crear un archivo nuevo en /etc/sudoers.d/user, esto es un ejemplo) y añadir una línea similar a la siguiente, sustituyendo user por el nombre de tu usuario:   user ALL=(ALL) NOPASSWD: ALL     Esto permite a user ejecutar comandos como root con sudo sin pedir contraseña.   Verificación del Nombre de Host (FQDN)   Es crucial que el nombre de host del servidor esté configurado como un Nombre de Dominio Completamente Cualificado (FQDN). Esto asegura una comunicación adecuada entre los servicios de AAP.   Podemos verificarlo con el siguiente comando:   hostname -f     Si no devuelve un FQDN, debemos configurarlo en nuestro sistema RHEL.   Gestión de Suscripciones y Repositorios   Para acceder a los paquetes y contenedores de Red Hat, el servidor RHEL debe estar correctamente suscrito y los repositorios necesarios deben estar habilitados.   Nos aseguramos de que el sistema está suscrito a Red Hat y que tiene acceso a los repositorios BaseOS y AppStream. Podemos comprobar el estado de la suscripción con:   sudo subscription-manager status     Si no está suscrito, podemos registrarlo con:   sudo subscription-manager register   Es necesario que los repositorios de AppStream y BaseOS estén habilitados, para ello verificamos que los tenemos activos. Aquí tenemos una imagen que muestra cómo verificar los repositorios activos:      Siguiente paso, instalamos el paquete ansible-core, que el instalador de AAP utilizará.  sudo dnf install ansible-core -y     Y opcionalmente podemos instalar los paquetes wget, git-core, rsync y vim que nos pueden ser útiles durante la instalación:   sudo dnf install wget git-core rsync vim -y   Descarga del Instalador de Ansible Automation Platform   Visitamos el portal de descargas de Ansible Automation Platform. Desde allí es posible obtener las versiones más recientes del instalador.   Existen dos modalidades principales de instalación:      Instalación Online: Selecciona la opción “Ansible Automation Platform 2.5 Containerized Setup”. En este caso, durante el proceso de instalación, el instalador descargará los contenedores necesarios directamente desde los repositorios de Red Hat.   Instalación Offline (paquete completo): Selecciona la opción “Ansible Automation Platform 2.5 Containerized Setup Bundle”. Este paquete incluye todos los artefactos requeridos para entornos aislados de Internet o con restricciones de red.   Nosotros para esta guía elegiremos la online, una vez elegida la modalidad, descargamos el archivo .tar.gz correspondiente a la versión y arquitectura del sistema.   Aquí tenemos una imagen que ilustra la descarga desde el portal:      Los archivos descargados deben copiarse a la máquina donde se realizará la instalación. Esto suele hacerse desde la estación de administración hacia el servidor RHEL destino.   La forma más segura de realizar esta transferencia es mediante SCP (Secure Copy Protocol).   En el servidor RHEL, tendremos que definir un directorio que servirá como punto de instalación.   Requisito importante: debemos asegurarnos de contar con al menos 15 GB de espacio libre en el directorio seleccionado, ya que la instalación inicial genera múltiples contenedores y datos temporales.   En este caso utilizaremos /home/user/demos para descomprimir el archivo tar:   mkdir -p /home/user/demos   df -h /home/user/demos     Con los archivos ya presentes en el servidor, vamos a descomprimir el instalador en el directorio demos.   tar -xvzf ansible-automation-platform-setup-2.5-containerized-tar.gz -C /home/user/demos     Al finalizar, se creará un directorio con todos los archivos y scripts necesarios para continuar con el despliegue de la plataforma.   Configuración del Archivo de Inventario      Cuando instalamos Ansible Automation Platform (AAP), todo gira en torno a un archivo llamado inventory. Este archivo es como el “mapa” que le dice al instalador qué componentes debe desplegar, en qué servidores y con qué configuraciones.   Sin este archivo, el instalador no sabe qué hacer, así que aquí te explico cómo funciona y cómo puedes adaptarlo a tu entorno.   Dentro del paquete de instalación que hemos descargado vienen ejemplos de inventario:      inventory: pensado para instalaciones enterprise (distribuidas, con varios nodos).   inventory-growth: pensado para instalaciones all-in-one (todo en un mismo servidor).      La topología que queremos implementar es la growth, vamos a modificar el inventory-growth para que se ajuste a nuestra configuración.   Para ello abrimos el archivo y añadimos nuestro fqdn y credenciales de Red Hat en los campos necesarios. El archivo se verá similar a este:   # This is the AAP installer inventory file intended for the Container growth deployment topology.   # This inventory file expects to be run from the host where AAP will be installed.   # Please consult the Ansible Automation Platform product documentation about this topology's tested hardware configuration.   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/tested_deployment_models/container-topologies   #   # Please consult the docs if you're unsure what to add   # For all optional variables please consult the included README.md   # or the Ansible Automation Platform documentation:   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation     # This section is for your AAP Gateway host(s)   # -----------------------------------------------------   [automationgateway]   your.fqdn.here     # This section is for your AAP Controller host(s)   # -----------------------------------------------------   [automationcontroller]   your.fqdn.here     # This section is for your AAP Automation Hub host(s)   # -----------------------------------------------------   [automationhub]   your.fqdn.here     # This section is for your AAP EDA Controller host(s)   # -----------------------------------------------------   [automationeda]   your.fqdn.here     # This section is for the AAP database   # -----------------------------------------------------   [database]   your.fqdn.here     [all:vars]   # Ansible   ansible_connection=local     # Common variables   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#ref-general-inventory-variables   # -----------------------------------------------------   postgresql_admin_username=postgres   postgresql_admin_password=your_postgresql_admin_password     registry_username=your_rhn_username   registry_password=your_rhn_password     redis_mode=standalone     # AAP Gateway   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#ref-gateway-variables   # -----------------------------------------------------   gateway_admin_password=your_gateway_admin_password   gateway_pg_host=your.fqdn.here   gateway_pg_password=your_gateway_pg_password     # AAP Controller   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#ref-controller-variables   # -----------------------------------------------------   controller_admin_password=your_controller_admin_password   controller_pg_host=your.fqdn.here   controller_pg_password=your_controller_pg_password   controller_percent_memory_capacity=0.5     # AAP Automation Hub   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#ref-hub-variables   # -----------------------------------------------------   hub_admin_password=your_hub_admin_password   hub_pg_host=your.fqdn.here   hub_pg_password=your_hub_pg_password   hub_seed_collections=false     # AAP EDA Controller   # https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html/containerized_installation/appendix-inventory-files-vars#event-driven-ansible-controller   # -----------------------------------------------------   eda_admin_password=your_eda_admin_password   eda_pg_host=your.fqdn.here   eda_pg_password=your_eda_pg_password    Sustituimos your.fqdn.here por el fqdn de nuestra instancia donde instalaremos el Ansible Automation Platform.   Modificamos el &lt;set your own&gt; por las contraseñas que queramos para nuestro usuario admin en cada componente que se indica en el inventario.   Y en los campos registry_username=your_rhn_username y registry_password=your_rhn_password indicamos nuestro usuario y contraseña de la cuenta de Red Hat.   Una vez lo tenemos todo listo podemos lanzar el instalador y indicar el archivo de inventario correspondiente (opción -i). Nos tenemos que assegurar de estar en el directorio donde descomprimimos el instalador (e.g., /home/user/demos/ansible-automation-platform-containerized-setup-2.5-19).   cd /home/user/demos/ansible-automation-platform-containerized-setup-2.5-19 ansible-playbook -i inventory-growth ansible.containerized_installer.install      Cuando finalice la instalación de Ansible Automation Platform (AAP), el siguiente paso es comprobar que la interfaz web esté disponible.   De manera predeterminada, podemos acceder escribiendo en el navegador:   https://&lt;gateway_node&gt;:443   Aquí reemplazar &lt;gateway_node&gt; por el nombre o la dirección IP del servidor donde desplegamos el Automation Gateway.   Para entrar al panel, utilizar el usuario admin (gateway_admin_username) y la contraseña que definiste en la instalación (gateway_admin_password).   Aquí tenemos una captura de pantalla de la pantalla de inicio de sesión de AAP:    Para habilitar el soporte completo y recibir actualizaciones, debemos activar la suscripción de Ansible Automation Platform. Dentro de la interfaz web, nos dirigimos a la sección de administración de suscripciones e introducimos nuestras credenciales de acceso de Red Hat (Client ID y Client Secret).      Finalmente, ya accedemos, ahora podemos empezar a explorar todas las capacidades de automatización que ofrece Ansible Automation Platform.      Mi idea con este artículo era desmitificar el proceso, compartir esa “receta” que a mí me ha funcionado bien para arrancar rápido con una topología “Growth”. Podemos pensar en ella como un campo de pruebas personal, donde podemos cacharrear, aprender y, lo más importante, empezar a ver lo que ofrece AAP sin el estrés de una configuración gigante y con una gran flexibilidad para crecer cuando nosotros queramos.  ","categories": ["Automation","Ansible","RedHat"],
        "tags": ["AAP","AnsibleAutomationPlatform","RHEL","InstallationGuide","Containerized"],
        "url": "/automation/ansible/redhat/AAP-Guia-de-instalacion-2.5/",
        "teaser": null
      },{
        "title": "Red Hat Enterprise Linux: Integración de RHEL 10 con Active Directory 2019 usando SSSD y realmd",
        "excerpt":"Integración de RHEL 10 con Active Directory 2019 usando SSSD y realmd   Introducción   La gestión centralizada de identidades y accesos es clave. Microsoft Active Directory (AD) se ha consolidado como el estándar en muchas infraestructuras para esta tarea.   En esta guía, desglosaremos las opciones de integración y veremos paso a paso cómo conectar un sistema RHEL a un dominio de Active Directory.   Opciones de Integración: ¿Cuál elegir?   Existen varias formas de lograr esta integración, cada una con sus particularidades. Aquí te presentamos las principales:   Tabla de opciones de integración                  Opción de Integración       Descripción Técnica                       System Security Services Daemon (SSSD)       Es el componente de autenticación y resolución de identidades más moderno y recomendado. Permite a RHEL integrarse de forma nativa con dominios Active Directory utilizando protocolos como Kerberos, LDAP y DNS. Ofrece funcionalidades avanzadas como caché de credenciales, resolución de grupos y usuarios, mapeo de atributos AD a NSS/PAM, y soporte para autenticación offline. SSSD actúa como un middleware entre las aplicaciones del sistema y las fuentes externas de identidad, centralizando la gestión de políticas y sesiones.                 Samba Winbind       Implementación basada en Samba que permite a los sistemas Linux funcionar como miembros de un dominio Windows/AD. Utiliza protocolos SMB/CIFS, NTLM y Kerberos, proporcionando resolución de usuarios y grupos de dominio a través de nsswitch y PAM. Aunque es funcional, su arquitectura basada en SMB puede implicar una mayor carga y dependencia del stack de Samba en comparación con SSSD.                 Managed Service Account (MSA)       Una característica de Active Directory que permite crear cuentas de servicio administradas. Diseñada para que aplicaciones o demonios específicos en RHEL se autentiquen contra AD de forma segura sin requerir la unión completa del host al dominio. Las MSA gestionan automáticamente la rotación de contraseñas y las políticas de autenticación mediante Kerberos, reduciendo la sobrecarga administrativa y los riesgos asociados a credenciales estáticas. Ideal para servicios, no para login de usuarios interactivos.           En esta guía, nos centraremos en el método más recomendado y versátil para una integración profunda: SSSD.   Descubriendo SSSD   El System Security Services Daemon (SSSD) es un servicio esencial en los sistemas Linux/UNIX que actúa como intermediario inteligente para la gestión de identidad y autenticación. Su propósito es conectar tu sistema local (el “cliente SSSD”) a diversas fuentes de identidad y mecanismos de autenticación remotos (los “proveedores”).   SSSD opera en dos etapas clave:      Conexión con el proveedor remoto: Se comunica con un proveedor remoto (LDAP, AD, Kerberos, IdM) para obtener información de identidad del usuario (UID, GID, etc.) y datos necesarios para autenticación.   Caché local de identidad y credenciales: Crea y mantiene una caché local de esta información, permitiendo autenticación offline y mejor rendimiento.   Gracias a esta arquitectura, los usuarios pueden autenticarse en Linux usando cuentas almacenadas en el proveedor remoto sin crear cuentas locales duplicadas. SSSD puede configurarse para crear directorios de inicio automáticamente.   Los Pilares de la Autenticación: PAM y NSS   SSSD obtiene la información de identidad desde un servidor remoto y la almacena localmente. ¿Cómo utiliza el sistema operativo esa información?   PAM (Pluggable Authentication Modules)      Función: Autenticación y autorización de usuarios.   Pregunta clave: “¿Puede este usuario autenticarse y acceder?”   NSS (Name Service Switch)      Función: Define de dónde obtener información sobre usuarios, grupos, hosts, contraseñas, etc.   Archivo de configuración: /etc/nsswitch.conf   passwd:     files ldap sss group:      files ldap sss shadow:     files ldap sss hosts:      files dns sss  Esto significa que, para passwd (usuarios), el sistema primero busca en /etc/passwd (files), luego en un servidor LDAP (ldap), y finalmente consulta a SSSD (sss).      Pregunta clave: “¿De dónde obtengo la información de este usuario (UID, GID, nombre)?”   Flujo de Autenticación Detallado      Requisitos y Opciones de Mapeo de IDs   Tipos de Servidores de Identidad Compatibles con SSSD   SSSD es altamente versátil y puede interactuar con diversas fuentes de identidad:                  Tipo de Servidor       Descripción                       Active Directory (AD)       Servicio de directorio de Microsoft que proporciona autenticación, autorización y políticas centralizadas, el foco de nuestro artículo.                 Identity Management (IdM) en RHEL       Implementación de gestión de identidades integrada en RHEL basada en FreeIPA, ideal para entornos Linux puros o híbridos compatibles con AD.                 Servidores genéricos LDAP o Kerberos       Sistemas de directorio o autenticación basados en estándares abiertos que proporcionan servicios de identidad sin la complejidad inherente de Active Directory o las características de IdM.           POSIX ID Mapping vs. POSIX Attributes   Cuando integramos Linux con Active Directory, nos enfrentamos a una diferencia fundamental: cómo manejan las identidades los usuarios.      Linux utiliza UID (User ID) y GID (Group ID), siguiendo el estándar POSIX.   Windows AD utiliza SID (Security ID), un identificador único globalmente.   Para que un usuario de Active Directory pueda acceder a un sistema Linux, necesitamos traducir o asignar esos identificadores de Windows (SID) a los de Linux (UID/GID).  Aquí es donde SSSD ofrece dos opciones principales:      POSIX ID Mapping   POSIX Attributes   POSIX ID Mapping (mapeo automático)      Esta es la opción predeterminada.   En este modo, SSSD genera automáticamente los UID y GID a partir del SID de cada usuario de AD mediante un algoritmo interno.   Así, no es necesario modificar nada dentro de Active Directory.   POSIX Attributes (atributos POSIX en AD)      En este modo, los UID y GID se definen directamente en Active Directory, utilizando los atributos POSIX estándar (como uidNumber, gidNumber, unixHomeDirectory, etc.).   SSSD simplemente lee esos valores cuando el usuario inicia sesión.   Requiere editar o extender el esquema de AD para incluir los atributos POSIX, y la configuración es más compleja.   ¡Demo! Integrando RHEL con Active Directory   En esta práctica, integraremos un sistema RHEL 10 a un dominio de Active Directory 2019 utilizando SSSD y el método de POSIX ID Mapping.   Utilizaremos un dominio ficticio para fines educativos: umbrella.corp.   El objetivo es permitir que los usuarios de Active Directory puedan autenticarse directamente en Linux con su nombre de usuario y contraseña de AD, sin necesidad de crear cuentas locales en RHEL.  Gracias a SSSD y POSIX ID Mapping, RHEL asignará automáticamente los UID y GID a los usuarios de AD, garantizando una identidad única dentro del sistema Linux sin modificar Active Directory.     Información de los Sistemas   RHEL 10.0                  Campo       Valor                       Hostname       leon                 IP       192.168.6.4                 Sistema Operativo       RHEL 10.0                 Rol       Servidor Linux a integrar con Active Directory                 Dominio       umbrella.corp                 DNS Primario       192.168.6.7                 Estado Integración AD       Pendiente                 Comentarios       Usará SSSD y realmd para unir al dominio             Windows Server 2019 (Active Directory / DNS)                  Campo       Valor                       Hostname       WIN-TURSKABH596                 IP       192.168.6.7                 Sistema Operativo       Windows Server 2019                 Rol       Controlador de Dominio / DNS                 Dominio       umbrella.corp                 DNS Primario       192.168.6.7                 Comentarios       Servidor principal del dominio, provee DNS interno                Nota:  El controlador de dominio también funciona como servidor DNS del dominio.  Esto es importante porque Active Directory depende del DNS para localizar controladores de dominio y otros servicios.  RHEL apunta a este DNS para poder resolver nombres dentro del dominio y autenticar usuarios correctamente.      Requisitos previos   Antes de empezar, hay que asegurarse de que el entorno tiene:      Conectividad de red Los puertos necesarios para la comunicación con AD deben estar abiertos.                  Servicio       Puerto       Protocolo       Notas                       DNS       53       UDP y TCP       —                 LDAP       389       UDP y TCP       —                 LDAPS       636       TCP       Opcional                 Samba       445       UDP y TCP       Para los Objetos de Directiva de Grupo (GPO)                 Kerberos       88       UDP y TCP       —                 Kerberos (kadmin)       464       UDP y TCP       Usado por kadmin para establecer y cambiar contraseñas                 Catálogo Global LDAP       3268       TCP       Si se usa la opción id_provider = ad                 Catálogo Global LDAPS       3269       TCP       Opcional                 NTP       123       UDP       Opcional                 NTP       323       UDP       Opcional                Configuración DNS   El servidor DNS de tu RHEL debe apuntar al controlador de dominio de Active Directory.  Puedes verificarlo en /etc/resolv.conf.            Sincronización de hora (NTP)   La hora del sistema RHEL debe estar sincronizada con el AD.  Esto es crítico para el correcto funcionamiento de Kerberos.        Empecemos con la instalación   Para empezar, instalamos los paquetes esenciales para la integración con Active Directory y el funcionamiento de SSSD:   sudo dnf install samba-common-tools realmd oddjob oddjob-mkhomedir sssd adcli krb5-workstation     Una vez instalados los paquetes, podemos usar realm discover para verificar la existencia y obtener información sobre nuestro dominio de Active Directory   realm discover ad.example.com      Es normal que el configured salga como no antes de unirse al dominio.   Antes de unir RHEL al dominio, es necesario ajustar las políticas criptográficas para soportar algunas configuraciones de Active Directory más antiguas   sudo update-crypto-policies --set DEFAULT:AD-SUPPORT-LEGACY      Se recomienda hacer un reboot para que se apliquen las politicas, es necessario reiniciar los servicios para que se aplique y con el reboot se inician todos de nuevo…   Esto permite que el sistema Linux utilice algoritmos y protocolos de cifrado compatibles con versiones de Active Directory que aún no soportan las políticas criptográficas más estrictas de RHEL 10 por defecto. Si no se aplica este ajuste, el intento de unir el dominio (realm join) puede fallar debido a incompatibilidades de cifrado o autenticación.   Ahora, el paso crucial, unir el sistema RHEL al dominio de Active Directory. El comando realm join no solo une el equipo, sino que también configura SSSD automáticamente con los parámetros adecuados. Te pedirá la contraseña de un usuario con permisos para unir equipos al dominio (por ejemplo, el usuario Administrator de AD).   sudo realm join ad.example.com -v       Para comprobar que la integración ha sido exitosa y que los usuarios de Active Directory son reconocidos en RHEL, podemos usar el comando getent passwd con un usuario de AD.   getent passwd administrator@ad.example.com     Ahora RHEL ja está integrado con Active Directory. Cualquier usuario de AD puede iniciar sesión en RHEL utilizando las credenciales de dominio  ","categories": ["RedHat","ActiveDirectory"],
        "tags": ["RHEL","ActiveDirectory","SSSD"],
        "url": "/redhat/activedirectory/RHEL-Integracion-RHEL-10-con-AD/",
        "teaser": null
      },,{
    "title": "Sobre mí",
    "excerpt":"¡Bienvenido/a a mi espacio digital! Soy técnico DevOps y trabajo en una consultoría tecnológica, dando soporte a clientes con sus sistemas y participando en proyectos de infraestructura IT. Me gusta aprender sobre diferentes tecnologías y ponerlas en práctica   Este espacio nació para compartir lo que voy aprendiendo y haciendo, me sirve para no perder detalles de mis proyectos y, de paso, espero que también pueda ser útil para quien esté pasando por algo parecido.   Tecnologías                                    ","url": "http://localhost:4000/about/"
  },{
    "title": "Blog",
    "excerpt":" ","url": "http://localhost:4000/blog/"
  },{
    "title": "Xavi Vico Martí",
    "excerpt":"                                        Red Hat Enterprise Linux: Integración de RHEL 10 con Active Directory 2019 usando SSSD y realmd          Guía para integrar Red Hat Enterprise Linux 10.0 (RHEL 10) con Active Directory 2019, utilizando las herramientas SSSD y realmd          Leer más                                        Red Hat Ansible Automation Platform 2.5: Guía de Instalación en RHEL 10 (Topología Growth Contenerizada)        Leer más                            Nuevo       Seguridad Empresarial con Red Hat: Más Allá del Código Abierto                ","url": "http://localhost:4000/"
  }]
